{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2712bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment\n",
      "Python version: 3.12.0 (v3.12.0:0fb18b02c8, Oct  2 2023, 09:45:56) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "✓ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "workspace_root = Path().cwd()\n",
    "sys.path.insert(0, str(workspace_root / 'src'))\n",
    "\n",
    "print(f\"Project root: {workspace_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"✓ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6815d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Thesis pipeline utilities\n",
    "from thesis_pipeline.io.paths import get_data_path\n",
    "from thesis_pipeline.io.parquet import read_parquet, write_parquet\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60945309",
   "metadata": {},
   "source": [
    "## 1. Load Submissions and Comments from Gold Layer\n",
    "\n",
    "Load monthly submissions and comments, then merge to create thread pseudo-documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7629ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold submissions: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit/submissions\n",
      "Gold comments: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit/comments\n",
      "Output: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "gold_submissions = get_data_path('gold') / 'reddit' / 'submissions'\n",
    "gold_comments = get_data_path('gold') / 'reddit' / 'comments'\n",
    "output_path = get_data_path('qa', 'reddit', create=True)\n",
    "\n",
    "print(f\"Gold submissions: {gold_submissions}\")\n",
    "print(f\"Gold comments: {gold_comments}\")\n",
    "print(f\"Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b7653da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016-09 submissions: 386,214\n",
      "Loaded 2016-10 submissions: 537,217\n",
      "\n",
      "Total submissions: 923,431\n",
      "Columns: ['submission_id', 'title', 'selftext', 'created_utc', 'subreddit_id', 'subreddit', 'num_comments']\n",
      "\n",
      "Sample:\n",
      "  submission_id                                              title selftext  \\\n",
      "0        50kc6b  Third Party Politics To combat Two Party Polit...            \n",
      "1        50kc7a  Italy told to brace itself for 'September assa...            \n",
      "\n",
      "   created_utc subreddit_id         subreddit  num_comments  \n",
      "0   1472688004     t5_2cneq          politics             1  \n",
      "1   1472688011     t5_3bwj3  abetterworldnews             0  \n"
     ]
    }
   ],
   "source": [
    "# Load submissions (monthly files)\n",
    "months = ['2016-09', '2016-10']\n",
    "\n",
    "submissions_dfs = []\n",
    "for month in months:\n",
    "    df = read_parquet(gold_submissions / f'{month}.parquet')\n",
    "    submissions_dfs.append(df)\n",
    "    print(f\"Loaded {month} submissions: {len(df):,}\")\n",
    "\n",
    "df_submissions = pd.concat(submissions_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal submissions: {len(df_submissions):,}\")\n",
    "print(f\"Columns: {df_submissions.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_submissions.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "22dda458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016-09 comments: 3,766,133\n",
      "Loaded 2016-10 comments: 4,932,790\n",
      "\n",
      "Total comments: 8,698,923\n",
      "Columns: ['comment_id', 'submission_id', 'created_utc', 'subreddit_id', 'subreddit', 'body']\n",
      "\n",
      "Unique submissions referenced: 501,969\n"
     ]
    }
   ],
   "source": [
    "# Load comments (monthly files)\n",
    "comments_dfs = []\n",
    "for month in months:\n",
    "    df = read_parquet(gold_comments / f'{month}.parquet')\n",
    "    comments_dfs.append(df)\n",
    "    print(f\"Loaded {month} comments: {len(df):,}\")\n",
    "\n",
    "df_comments = pd.concat(comments_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal comments: {len(df_comments):,}\")\n",
    "print(f\"Columns: {df_comments.columns.tolist()}\")\n",
    "print(f\"\\nUnique submissions referenced: {df_comments['submission_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44a81d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering bot comments...\n",
      "  Before: 8,545,756\n",
      "  After: 8,518,578\n",
      "  Removed: 27,178 bot comments (0.3%)\n"
     ]
    }
   ],
   "source": [
    "# Filter out bot comments using regex patterns\n",
    "import re\n",
    "\n",
    "print(\"\\nFiltering bot comments...\")\n",
    "before_filter = len(df_comments)\n",
    "print(f\"  Before: {before_filter:,}\")\n",
    "\n",
    "# Regex patterns for common bots\n",
    "bot_patterns = [\n",
    "    # AutoModerator removal messages\n",
    "    r\"Hi\\s+\\[`[a-zA-Z0-9_]+`\\].*mods.*Thank you for participating.*has been removed\",\n",
    "    r\"Your (comment|submission) has been (removed|automatically removed)\",\n",
    "    r\"I am a bot,?\\s+and this action was performed automatically\",\n",
    "    \n",
    "    # AutoTLDR bot\n",
    "    r\"\\*\\*TL;?DR\\*\\*\\s*:?\\s*This is the best tl;?dr I could make\",\n",
    "    r\"autotldr\",\n",
    "    \n",
    "    # Common bot signatures\n",
    "    r\"\\^(this|I'm|I am) \\^(is |am )?a \\^bot\",\n",
    "    r\"I('m| am) a bot\",\n",
    "    r\"\\[\\]\\(/GNU Terry Pratchett\\)\",  # Memorial bot - fixed: escaped the (\n",
    "    \n",
    "    # URL preview bots\n",
    "    r\"Image\\(s\\) rehosted on\",\n",
    "    r\"Original.*\\(bot\\)\",\n",
    "]\n",
    "\n",
    "# Compile patterns\n",
    "compiled_patterns = [re.compile(pattern, re.IGNORECASE | re.DOTALL) for pattern in bot_patterns]\n",
    "\n",
    "# Filter using regex\n",
    "def is_bot_comment(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    for pattern in compiled_patterns:\n",
    "        if pattern.search(text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_comments = df_comments[~df_comments['body'].apply(is_bot_comment)].copy()\n",
    "\n",
    "after_filter = len(df_comments)\n",
    "removed = before_filter - after_filter\n",
    "print(f\"  After: {after_filter:,}\")\n",
    "print(f\"  Removed: {removed:,} bot comments ({removed/before_filter*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9b6cb",
   "metadata": {},
   "source": [
    "## 2. Create Thread Pseudo-Documents\n",
    "\n",
    "Combine submission text with all comments to create thread-level documents for topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8afcf83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation:\n",
      "  Submissions: 923,431\n",
      "  Comments: 8,518,578\n",
      "  Submissions with missing title: 0\n",
      "  Submissions with missing selftext: 0\n",
      "  Comments with missing body: 0\n",
      "\n",
      "Date ranges:\n",
      "  Submissions: 2016-09-01 to 2016-10-31\n",
      "  Comments: 2016-09-01 to 2016-10-31\n"
     ]
    }
   ],
   "source": [
    "# Validate data\n",
    "print(\"Data validation:\")\n",
    "print(f\"  Submissions: {len(df_submissions):,}\")\n",
    "print(f\"  Comments: {len(df_comments):,}\")\n",
    "print(f\"  Submissions with missing title: {df_submissions['title'].isna().sum()}\")\n",
    "print(f\"  Submissions with missing selftext: {df_submissions['selftext'].isna().sum()}\")\n",
    "print(f\"  Comments with missing body: {df_comments['body'].isna().sum()}\")\n",
    "\n",
    "# Date ranges\n",
    "sub_dates = pd.to_datetime(df_submissions['created_utc'], unit='s')\n",
    "com_dates = pd.to_datetime(df_comments['created_utc'], unit='s')\n",
    "print(f\"\\nDate ranges:\")\n",
    "print(f\"  Submissions: {sub_dates.min().date()} to {sub_dates.max().date()}\")\n",
    "print(f\"  Comments: {com_dates.min().date()} to {com_dates.max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a424028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping comments by submission...\n",
      "Grouped into 433,973 submissions with comments\n",
      "Comments per submission: min=1, median=3, max=24156\n"
     ]
    }
   ],
   "source": [
    "# Group comments by submission\n",
    "print(\"Grouping comments by submission...\")\n",
    "\n",
    "comment_groups = df_comments.groupby('submission_id').agg({\n",
    "    'body': lambda x: ' '.join(x.fillna('').astype(str)),\n",
    "    'comment_id': 'count'\n",
    "}).rename(columns={'body': 'all_comments_text', 'comment_id': 'n_comments'}).reset_index()\n",
    "\n",
    "print(f\"Grouped into {len(comment_groups):,} submissions with comments\")\n",
    "print(f\"Comments per submission: min={comment_groups['n_comments'].min()}, \"\n",
    "      f\"median={comment_groups['n_comments'].median():.0f}, \"\n",
    "      f\"max={comment_groups['n_comments'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36fca357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating thread pseudo-documents...\n",
      "\n",
      "Created 923,431 thread pseudo-documents\n",
      "  With comments: 433,973\n",
      "  Without comments: 489,458\n"
     ]
    }
   ],
   "source": [
    "# Merge submissions with comment aggregations\n",
    "print(\"Creating thread pseudo-documents...\")\n",
    "\n",
    "# Clean submission text\n",
    "df_submissions['title'] = df_submissions['title'].fillna('').astype(str)\n",
    "df_submissions['selftext'] = df_submissions['selftext'].fillna('').astype(str)\n",
    "\n",
    "# Merge\n",
    "thread_pseudodocs = df_submissions.merge(\n",
    "    comment_groups, \n",
    "    on='submission_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values (submissions with no comments)\n",
    "thread_pseudodocs['all_comments_text'] = thread_pseudodocs['all_comments_text'].fillna('')\n",
    "thread_pseudodocs['n_comments'] = thread_pseudodocs['n_comments'].fillna(0).astype(int)\n",
    "\n",
    "# Create pseudo-document: title + selftext + all comments\n",
    "thread_pseudodocs['pseudodoc_text'] = (\n",
    "    thread_pseudodocs['title'] + ' ' + \n",
    "    thread_pseudodocs['selftext'] + ' ' + \n",
    "    thread_pseudodocs['all_comments_text']\n",
    ").str.strip()\n",
    "\n",
    "print(f\"\\nCreated {len(thread_pseudodocs):,} thread pseudo-documents\")\n",
    "print(f\"  With comments: {(thread_pseudodocs['n_comments'] > 0).sum():,}\")\n",
    "print(f\"  Without comments: {(thread_pseudodocs['n_comments'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2a592847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering to submissions with >= 1 comment...\n",
      "  Before: 923,431\n",
      "  After: 433,973\n",
      "  Removed: 489,458 submissions without replies\n",
      "\n",
      "✓ Final thread pseudo-documents: 433,973\n",
      "Columns: ['submission_id', 'title', 'selftext', 'n_comments', 'pseudodoc_text', 'pseudodoc_length', 'pseudodoc_tokens_approx', 'title_length', 'selftext_length', 'created_utc', 'subreddit', 'subreddit_id']\n"
     ]
    }
   ],
   "source": [
    "# Filter to only submissions with at least one comment\n",
    "# (No discussion = cannot measure polarization)\n",
    "print(f\"\\nFiltering to submissions with >= 1 comment...\")\n",
    "print(f\"  Before: {len(thread_pseudodocs):,}\")\n",
    "\n",
    "thread_pseudodocs = thread_pseudodocs[thread_pseudodocs['n_comments'] > 0].copy()\n",
    "\n",
    "print(f\"  After: {len(thread_pseudodocs):,}\")\n",
    "print(f\"  Removed: {len(df_submissions) - len(thread_pseudodocs):,} submissions without replies\")\n",
    "\n",
    "# Compute text statistics\n",
    "thread_pseudodocs['pseudodoc_length'] = thread_pseudodocs['pseudodoc_text'].str.len()\n",
    "thread_pseudodocs['pseudodoc_tokens_approx'] = thread_pseudodocs['pseudodoc_text'].str.split().str.len()\n",
    "thread_pseudodocs['title_length'] = thread_pseudodocs['title'].str.len()\n",
    "thread_pseudodocs['selftext_length'] = thread_pseudodocs['selftext'].str.len()\n",
    "\n",
    "# Select and order columns\n",
    "final_cols = [\n",
    "    'submission_id',\n",
    "    'title',\n",
    "    'selftext',\n",
    "    'n_comments',\n",
    "    'pseudodoc_text',\n",
    "    'pseudodoc_length',\n",
    "    'pseudodoc_tokens_approx',\n",
    "    'title_length',\n",
    "    'selftext_length',\n",
    "    'created_utc',\n",
    "    'subreddit',\n",
    "    'subreddit_id'\n",
    "]\n",
    "\n",
    "thread_pseudodocs = thread_pseudodocs[final_cols]\n",
    "\n",
    "print(f\"\\n✓ Final thread pseudo-documents: {len(thread_pseudodocs):,}\")\n",
    "print(f\"Columns: {thread_pseudodocs.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21656d59",
   "metadata": {},
   "source": [
    "## 3. Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5788aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "THREAD PSEUDO-DOCUMENT STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total threads with comments: 433,973\n",
      "Total submissions: 923,431\n",
      "Total comments: 8,518,578\n",
      "\n",
      "Metric                                 Mean       Median          Min          Max\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Thread statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"THREAD PSEUDO-DOCUMENT STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nTotal threads with comments: {len(thread_pseudodocs):,}\")\n",
    "print(f\"Total submissions: {len(df_submissions):,}\")\n",
    "print(f\"Total comments: {len(df_comments):,}\")\n",
    "\n",
    "print(f\"\\n{'Metric':<30} {'Mean':>12} {'Median':>12} {'Min':>12} {'Max':>12}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f97ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments/thread                        19.6            3            1        24156\n",
      "Pseudodoc length (chars)               4229          565           14      3908625\n",
      "Pseudodoc tokens (approx)               709           93            2       661246\n",
      "\n",
      "Unique subreddits: 353\n",
      "Top 5 subreddits:\n",
      "  The_Donald: 209,736\n",
      "  politics: 55,067\n",
      "  EnoughTrumpSpam: 16,194\n",
      "  hillaryclinton: 12,062\n",
      "  syriancivilwar: 8,853\n"
     ]
    }
   ],
   "source": [
    "# Comments per thread\n",
    "stats = thread_pseudodocs['n_comments'].describe()\n",
    "print(f\"{'Comments/thread':<30} {stats['mean']:>12.1f} {stats['50%']:>12.0f} {stats['min']:>12.0f} {stats['max']:>12.0f}\")\n",
    "\n",
    "# Pseudo-document length\n",
    "stats = thread_pseudodocs['pseudodoc_length'].describe()\n",
    "print(f\"{'Pseudodoc length (chars)':<30} {stats['mean']:>12.0f} {stats['50%']:>12.0f} {stats['min']:>12.0f} {stats['max']:>12.0f}\")\n",
    "\n",
    "# Tokens (approx)\n",
    "stats = thread_pseudodocs['pseudodoc_tokens_approx'].describe()\n",
    "print(f\"{'Pseudodoc tokens (approx)':<30} {stats['mean']:>12.0f} {stats['50%']:>12.0f} {stats['min']:>12.0f} {stats['max']:>12.0f}\")\n",
    "\n",
    "# Subreddit distribution\n",
    "print(f\"\\nUnique subreddits: {thread_pseudodocs['subreddit'].nunique():,}\")\n",
    "print(f\"Top 5 subreddits:\")\n",
    "for sub, count in thread_pseudodocs['subreddit'].value_counts().head(5).items():\n",
    "    print(f\"  {sub}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4063de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE PSEUDO-DOCUMENTS\n",
      "================================================================================\n",
      "\n",
      "Submission 50kc92:\n",
      "  Title: When is the speech?\n",
      "  Comments: 1\n",
      "  Subreddit: The_Donald\n",
      "  Length: 62 chars, ~14 tokens\n",
      "  Text preview: When is the speech?  I thought it was at 7 pm? like right now!...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Submission 568nrv:\n",
      "  Title: Jews make up 2% of US population, yet account for 50% of Hillary Clinton campaign contributions.\n",
      "  Comments: 15\n",
      "  Subreddit: altright\n",
      "  Length: 2,305 chars, ~384 tokens\n",
      "  Text preview: Jews make up 2% of US population, yet account for 50% of Hillary Clinton campaign contributions.  Am I supposed to be surprised? Its almost as if they have an enormous influence on our politics!!!\n",
      "\n",
      "But shhh. Jews are always the victims. Remember the holocaust? Shut up you neonazi! \\*sigh\\* Ugh. Maybe I'll write in \"Moon Man\" on my ballot. Trump or GTFO. He may not agree with us on all kinds of things but less beaners is a cause that America needs to embrace. It was kind of a joke. Plus I don't think my state offers a write-in option. You anti-semite! Remember the 60 trillion! 90 quadrillion!  Jews are successfull, they are significant in all industries. \n",
      "\n",
      "So what? Make up your mind - you can't hate \"certain groups\" for being lazy, uneducated, unemployed, unsuccessful bums on wellfare, but also hate the jews for being the opposite.  I don't hate anyone for being on welfare, I have people that plot against my people or people that make my society worse in quality.\n",
      "\n",
      "\n",
      "They shouldn't be this overrepresented, they need to have their assets seized  ...memba da Holocaust? Oy vey! Hatefacts! If you are for self-determination then this amount of influence by 2% of the population can't stand. There is a jewish ethnostate, and jews should move there. It is their country.\n",
      "\n",
      "Blacks have africa, it is time to repatriate them there so that they can \"enjoy\" their self rule and not have to worry about white police officers shooting them anymore.\n",
      "\n",
      "Whites also should have self determination and s...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Submission 5afnej:\n",
      "  Title: The Crowd Goes Wild as Trump Waves LGBT Flag During a Rally | One of the reasons why I cannot vote f\n",
      "  Comments: 15\n",
      "  Subreddit: Conservative\n",
      "  Length: 2,851 chars, ~476 tokens\n",
      "  Text preview: The Crowd Goes Wild as Trump Waves LGBT Flag During a Rally | One of the reasons why I cannot vote for Trump  Primarily, I am a social conservative and if that is the case then I cannot support these implicit concessions of gay marriage. Many Republicans want to abandon the issue but I cannot. i feel the opposite.  i'm happy to see a republican embracing homosexuals.\n",
      "\n",
      "\n",
      "\n",
      "are we seriously not doing phrasing anymore? You can't give what concessions? \n",
      "Getting equal rights for consenting individuals?\n",
      " It has nothing to do with equal rights and real complete conservatives recognize that. It just begs the question to assume that. Also considering your other social positions I can definitely see why gay marriage isn't on your agenda since unborn children do not matter to you.\n",
      "\n",
      "https://www.reddit.com/r/Conservative/comments/56hrrl/still_the_best_candidate_some_evangelicals_still/d8k2mia/?context=3 I'm the opposite. I've always voted for Republican candidates because of their stance on the 2nd amendment and the idea of less intrusion of government into our lives. That changed with the patriot act stuff and the stance on gay marriage. I'm personally against abortion, but I don't care what people are doing in their bedrooms, and neither should elected officials. I don't believe that anyone should be a protected class, but I also don't believe in making laws to prevent 2 consenting adults from living their lives. Get government out of marriage. The democrats do not want the government out...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample pseudo-documents\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE PSEUDO-DOCUMENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in [0, len(thread_pseudodocs)//2, -1]:\n",
    "    row = thread_pseudodocs.iloc[i]\n",
    "    print(f\"\\nSubmission {row['submission_id']}:\")\n",
    "    print(f\"  Title: {row['title'][:100]}\")\n",
    "    print(f\"  Comments: {row['n_comments']}\")\n",
    "    print(f\"  Subreddit: {row['subreddit']}\")\n",
    "    print(f\"  Length: {row['pseudodoc_length']:,} chars, ~{row['pseudodoc_tokens_approx']:,} tokens\")\n",
    "    print(f\"  Text preview: {row['pseudodoc_text'][:1500]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4785f1",
   "metadata": {},
   "source": [
    "## 4. Create Comment-Submission Mapping\n",
    "\n",
    "Map all comments to their submissions for stance detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d168a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comment-submission mapping...\n",
      "Valid submissions (with >= 1 comment): 433,973\n",
      "Comments from valid submissions: 8,518,578\n",
      "\n",
      "✓ Created mapping for 8,518,578 comments\n",
      "Columns: ['comment_id', 'submission_id', 'comment_body', 'comment_created_utc', 'subreddit', 'subreddit_id', 'title', 'selftext']\n"
     ]
    }
   ],
   "source": [
    "# Create comment-submission mapping for stance detection\n",
    "# Only include comments from threads that have discussion (n_comments > 0)\n",
    "\n",
    "print(\"Creating comment-submission mapping...\")\n",
    "\n",
    "valid_submissions = set(thread_pseudodocs['submission_id'].values)\n",
    "print(f\"Valid submissions (with >= 1 comment): {len(valid_submissions):,}\")\n",
    "\n",
    "# Filter comments to only those with valid submissions\n",
    "df_comments_filtered = df_comments[df_comments['submission_id'].isin(valid_submissions)].copy()\n",
    "print(f\"Comments from valid submissions: {len(df_comments_filtered):,}\")\n",
    "\n",
    "# Merge with submission info\n",
    "submission_info = thread_pseudodocs[['submission_id', 'title', 'selftext', 'subreddit', 'subreddit_id']].copy()\n",
    "\n",
    "comment_map = df_comments_filtered.merge(submission_info, on='submission_id', how='left', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Rename for clarity\n",
    "comment_map = comment_map.rename(columns={\n",
    "    'body': 'comment_body',\n",
    "    'created_utc': 'comment_created_utc',\n",
    "    'subreddit_comment': 'subreddit',  # Use comment's subreddit (should match submission's)\n",
    "    'subreddit_id_comment': 'subreddit_id'\n",
    "})\n",
    "\n",
    "# Select final columns\n",
    "final_cols = [\n",
    "    'comment_id',\n",
    "    'submission_id',\n",
    "    'comment_body',\n",
    "    'comment_created_utc',\n",
    "    'subreddit',\n",
    "    'subreddit_id',\n",
    "    'title',\n",
    "    'selftext'\n",
    "]\n",
    "\n",
    "comment_map = comment_map[final_cols]\n",
    "\n",
    "print(f\"\\n✓ Created mapping for {len(comment_map):,} comments\")\n",
    "print(f\"Columns: {comment_map.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d2a700db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating thread metadata...\n",
      "✓ Created metadata for 433,973 threads\n",
      "Columns: ['submission_id', 'title', 'n_comments', 'created_utc', 'subreddit']\n"
     ]
    }
   ],
   "source": [
    "# Create thread metadata\n",
    "print(\"\\nCreating thread metadata...\")\n",
    "\n",
    "thread_metadata = thread_pseudodocs[['submission_id', 'title', 'n_comments', 'created_utc', 'subreddit']].copy()\n",
    "\n",
    "print(f\"✓ Created metadata for {len(thread_metadata):,} threads\")\n",
    "print(f\"Columns: {thread_metadata.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5c2d246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA QUALITY VERIFICATION\n",
      "============================================================\n",
      "\n",
      "Comment breakdown:\n",
      "  Total comments: 8,518,578\n",
      "  Submissions (comment_id == submission_id): 0\n",
      "  Replies (comment_id != submission_id): 8,518,578\n",
      "\n",
      "Sample thread verification (submission_id: 50la9v):\n",
      "  n_comments from metadata: 1\n",
      "\n",
      "\n",
      "  Total comments in map: 1\n",
      "\n",
      "\n",
      "  Submission title: Cubism Titled: Sick Woman Finally Opens Pre-Opened Pickle Jar as Confused Host Looks On\n",
      "  Submission selftext: ...\n",
      "Comments for submission_id 50la9v:\n",
      "\n",
      "First 3 comments from this thread:\n",
      "  Comment d74yzms: Should be hanging in the MoMA ...\n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check that submissions and replies are properly separated\n",
    "print(f\"\\nComment breakdown:\")\n",
    "print(f\"  Total comments: {len(comment_map):,}\")\n",
    "print(f\"  Submissions (comment_id == submission_id): {(comment_map['comment_id'] == comment_map['submission_id']).sum():,}\")\n",
    "print(f\"  Replies (comment_id != submission_id): {(comment_map['comment_id'] != comment_map['submission_id']).sum():,}\")\n",
    "\n",
    "# Sample a thread to verify structure\n",
    "sample_thread = thread_pseudodocs.iloc[1000]\n",
    "print(f\"\\nSample thread verification (submission_id: {sample_thread['submission_id']}):\")\n",
    "print(f\"  n_comments from metadata: {sample_thread['n_comments']}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "# Get all comments for this thread\n",
    "thread_comments = comment_map[comment_map['submission_id'] == sample_thread['submission_id']].sort_values('comment_created_utc')\n",
    "print(f\"  Total comments in map: {len(thread_comments)}\")\n",
    "\n",
    "# Show first few comments to verify structure\n",
    "print(\"\\n\")\n",
    "print(f\"  Submission title: {sample_thread['title']}\")\n",
    "print(f\"  Submission selftext: {sample_thread['selftext'][:200]}...\")\n",
    "print(f\"Comments for submission_id {sample_thread['submission_id']}:\")\n",
    "print(f\"\\nFirst 3 comments from this thread:\")\n",
    "for idx, row in thread_comments.head(3).iterrows():\n",
    "    print(f\"  Comment {row['comment_id']}: {row['comment_body'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459ebb6",
   "metadata": {},
   "source": [
    "## 5. Save Outputs\n",
    "\n",
    "Save three key outputs:\n",
    "1. **thread_pseudodocs.parquet**: Thread-level pseudo-documents (submission + all comments) for topic modeling\n",
    "2. **thread_metadata.parquet**: Thread-level statistics (submission_id, title, n_comments, created_utc, subreddit)\n",
    "3. **comment_thread_map.parquet**: All comments with full context for stance detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dcfb5a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving thread pseudo-documents...\n",
      "✓ Wrote 433,973 rows to thread_pseudodocs.parquet (1112.1 MB)\n",
      "✓ Saved 433,973 thread pseudo-documents\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/thread_pseudodocs.parquet\n",
      "\n",
      "Saving thread metadata...\n",
      "✓ Wrote 433,973 rows to thread_metadata.parquet (28.2 MB)\n",
      "✓ Saved 433,973 thread metadata records\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/thread_metadata.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save thread pseudo-documents\n",
    "print(\"Saving thread pseudo-documents...\")\n",
    "thread_output = output_path / 'thread_pseudodocs.parquet'\n",
    "write_parquet(thread_pseudodocs, thread_output)\n",
    "print(f\"✓ Saved {len(thread_pseudodocs):,} thread pseudo-documents\")\n",
    "print(f\"  Location: {thread_output}\")\n",
    "\n",
    "# Save thread metadata\n",
    "print(\"\\nSaving thread metadata...\")\n",
    "metadata_output = output_path / 'thread_metadata.parquet'\n",
    "write_parquet(thread_metadata, metadata_output)\n",
    "print(f\"✓ Saved {len(thread_metadata):,} thread metadata records\")\n",
    "print(f\"  Location: {metadata_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9815ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving comment-thread mapping...\n",
      "✓ Wrote 8,518,578 rows to comment_thread_map.parquet (2342.6 MB)\n",
      "✓ Saved 8,518,578 comments (submissions + replies)\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/comment_thread_map.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save comment-thread mapping with full context\n",
    "print(\"\\nSaving comment-thread mapping...\")\n",
    "comment_output = output_path / 'comment_thread_map.parquet'\n",
    "write_parquet(comment_map, comment_output)\n",
    "print(f\"✓ Saved {len(comment_map):,} comments (submissions + replies)\")\n",
    "print(f\"  Location: {comment_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974215fc",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "Generate metadata for this processing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f617516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUN SUMMARY\n",
      "============================================================\n",
      "\n",
      "Notebook: 14_reddit_corpus_prep_topics\n",
      "  Gold submissions: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit/submissions\n",
      "  Gold comments: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit/comments\n",
      "  Months: ['2016-09', '2016-10']\n",
      "  Submissions (raw): 923,431\n",
      "  Comments (raw): 8,518,578\n",
      "\n",
      "Outputs:\n",
      "  Thread pseudo-documents: 433,973\n",
      "  Comments in mapping: 8,518,578\n",
      "\n",
      "Summary saved to: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/run_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Create summary metadata\n",
    "summary = {\n",
    "    'notebook': '14_reddit_corpus_prep_topics',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'inputs': {\n",
    "        'gold_submissions': str(gold_submissions),\n",
    "        'gold_comments': str(gold_comments),\n",
    "        'months': months,\n",
    "        'n_submissions_raw': len(df_submissions),\n",
    "        'n_comments_raw': len(df_comments)\n",
    "    },\n",
    "    'outputs': {\n",
    "        'thread_pseudodocs': str(thread_output),\n",
    "        'comment_thread_map': str(comment_output),\n",
    "        'thread_metadata': str(metadata_output),\n",
    "        'n_threads': len(thread_pseudodocs),\n",
    "        'n_comments_in_map': len(comment_map)\n",
    "    },\n",
    "    'statistics': {\n",
    "        'comments_per_thread': {\n",
    "            'mean': float(thread_pseudodocs['n_comments'].mean()),\n",
    "            'median': float(thread_pseudodocs['n_comments'].median()),\n",
    "            'min': int(thread_pseudodocs['n_comments'].min()),\n",
    "            'max': int(thread_pseudodocs['n_comments'].max())\n",
    "        },\n",
    "        'pseudodoc_length_chars': {\n",
    "            'mean': float(thread_pseudodocs['pseudodoc_length'].mean()),\n",
    "            'median': float(thread_pseudodocs['pseudodoc_length'].median()),\n",
    "            'min': int(thread_pseudodocs['pseudodoc_length'].min()),\n",
    "            'max': int(thread_pseudodocs['pseudodoc_length'].max())\n",
    "        },\n",
    "        'pseudodoc_tokens_approx': {\n",
    "            'mean': float(thread_pseudodocs['pseudodoc_tokens_approx'].mean()),\n",
    "            'median': float(thread_pseudodocs['pseudodoc_tokens_approx'].median())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary to file\n",
    "summary_file = output_path / 'run_metadata.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUN SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNotebook: {summary['notebook']}\")\n",
    "print(f\"  Gold submissions: {summary['inputs']['gold_submissions']}\")\n",
    "print(f\"  Gold comments: {summary['inputs']['gold_comments']}\")\n",
    "print(f\"  Months: {summary['inputs']['months']}\")\n",
    "print(f\"  Submissions (raw): {summary['inputs']['n_submissions_raw']:,}\")\n",
    "print(f\"  Comments (raw): {summary['inputs']['n_comments_raw']:,}\")\n",
    "print(f\"\\nOutputs:\")\n",
    "print(f\"  Thread pseudo-documents: {summary['outputs']['n_threads']:,}\")\n",
    "print(f\"  Comments in mapping: {summary['outputs']['n_comments_in_map']:,}\")\n",
    "\n",
    "print(f\"\\nSummary saved to: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
