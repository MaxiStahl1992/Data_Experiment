{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2712bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment\n",
      "Python version: 3.12.0 (v3.12.0:0fb18b02c8, Oct  2 2023, 09:45:56) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "✓ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "workspace_root = Path().cwd()\n",
    "sys.path.insert(0, str(workspace_root / 'src'))\n",
    "\n",
    "print(f\"Project root: {workspace_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"✓ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6815d89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Thesis pipeline utilities\n",
    "from thesis_pipeline.io.paths import get_data_path\n",
    "from thesis_pipeline.io.parquet import read_parquet, write_parquet\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60945309",
   "metadata": {},
   "source": [
    "## 1. Load Reddit Gold Layer\n",
    "\n",
    "Load the thread-structured comments from notebook 12 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7629ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold layer: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit\n",
      "Output: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "gold_path = get_data_path('gold', 'reddit')\n",
    "output_path = get_data_path('qa', 'reddit', create=True)\n",
    "\n",
    "print(f\"Gold layer: {gold_path}\")\n",
    "print(f\"Output: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7653da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reddit gold layer...\n",
      "Found 61 parquet files\n",
      "  Loaded 2016-09-01.parquet: 109,184 comments\n",
      "  Loaded 2016-09-02.parquet: 98,775 comments\n",
      "  Loaded 2016-09-03.parquet: 74,731 comments\n",
      "  Loaded 2016-09-04.parquet: 80,990 comments\n",
      "  Loaded 2016-09-05.parquet: 85,066 comments\n",
      "  Loaded 2016-09-06.parquet: 110,391 comments\n",
      "  Loaded 2016-09-07.parquet: 105,031 comments\n",
      "  Loaded 2016-09-08.parquet: 123,756 comments\n",
      "  Loaded 2016-09-09.parquet: 98,605 comments\n",
      "  Loaded 2016-09-10.parquet: 87,648 comments\n",
      "  Loaded 2016-09-11.parquet: 138,072 comments\n",
      "  Loaded 2016-09-12.parquet: 153,446 comments\n",
      "  Loaded 2016-09-13.parquet: 142,864 comments\n",
      "  Loaded 2016-09-14.parquet: 137,999 comments\n",
      "  Loaded 2016-09-15.parquet: 132,073 comments\n",
      "  Loaded 2016-09-16.parquet: 143,633 comments\n",
      "  Loaded 2016-09-17.parquet: 111,225 comments\n",
      "  Loaded 2016-09-18.parquet: 110,791 comments\n",
      "  Loaded 2016-09-19.parquet: 148,111 comments\n",
      "  Loaded 2016-09-20.parquet: 154,930 comments\n",
      "  Loaded 2016-09-21.parquet: 138,415 comments\n",
      "  Loaded 2016-09-22.parquet: 144,055 comments\n",
      "  Loaded 2016-09-23.parquet: 134,682 comments\n",
      "  Loaded 2016-09-24.parquet: 105,681 comments\n",
      "  Loaded 2016-09-25.parquet: 102,135 comments\n",
      "  Loaded 2016-09-26.parquet: 141,567 comments\n",
      "  Loaded 2016-09-27.parquet: 284,161 comments\n",
      "  Loaded 2016-09-28.parquet: 147,935 comments\n",
      "  Loaded 2016-09-29.parquet: 135,857 comments\n",
      "  Loaded 2016-09-30.parquet: 130,836 comments\n",
      "  Loaded 2016-10-01.parquet: 102,991 comments\n",
      "  Loaded 2016-10-02.parquet: 107,017 comments\n",
      "  Loaded 2016-10-03.parquet: 131,381 comments\n",
      "  Loaded 2016-10-04.parquet: 142,385 comments\n",
      "  Loaded 2016-10-05.parquet: 169,042 comments\n",
      "  Loaded 2016-10-06.parquet: 119,611 comments\n",
      "  Loaded 2016-10-07.parquet: 130,476 comments\n",
      "  Loaded 2016-10-08.parquet: 169,904 comments\n",
      "  Loaded 2016-10-09.parquet: 143,190 comments\n",
      "  Loaded 2016-10-10.parquet: 300,025 comments\n",
      "  Loaded 2016-10-11.parquet: 161,582 comments\n",
      "  Loaded 2016-10-12.parquet: 168,756 comments\n",
      "  Loaded 2016-10-13.parquet: 182,091 comments\n",
      "  Loaded 2016-10-14.parquet: 164,325 comments\n",
      "  Loaded 2016-10-15.parquet: 135,963 comments\n",
      "  Loaded 2016-10-16.parquet: 138,284 comments\n",
      "  Loaded 2016-10-17.parquet: 179,637 comments\n",
      "  Loaded 2016-10-18.parquet: 188,674 comments\n",
      "  Loaded 2016-10-19.parquet: 175,878 comments\n",
      "  Loaded 2016-10-20.parquet: 282,475 comments\n",
      "  Loaded 2016-10-21.parquet: 160,980 comments\n",
      "  Loaded 2016-10-22.parquet: 119,790 comments\n",
      "  Loaded 2016-10-23.parquet: 119,293 comments\n",
      "  Loaded 2016-10-24.parquet: 146,802 comments\n",
      "  Loaded 2016-10-25.parquet: 140,856 comments\n",
      "  Loaded 2016-10-26.parquet: 155,386 comments\n",
      "  Loaded 2016-10-27.parquet: 153,547 comments\n",
      "  Loaded 2016-10-28.parquet: 196,605 comments\n",
      "  Loaded 2016-10-29.parquet: 144,141 comments\n",
      "  Loaded 2016-10-30.parquet: 143,028 comments\n",
      "  Loaded 2016-10-31.parquet: 199,035 comments\n",
      "\n",
      "Total loaded: 8,785,795 comments\n",
      "Columns: ['date', 'created_utc', 'comment_id', 'thread_id', 'is_top_level', 'author', 'subreddit', 'subreddit_id', 'body', 'cleaned_body', 'score', 'parent_id']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_top_level",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cleaned_body",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parent_id",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "76f02a7a-7c2f-4c94-a121-e75a955c7b13",
       "rows": [
        [
         "0",
         "2016-09-01",
         "1472688001",
         "d74qmz3",
         "50grgt",
         "False",
         "krb7H",
         "politics",
         "t5_2cneq",
         "trump seems to be gaining supporters at an increasing rate. I remember when he had single-digit chances of winning. Now it almost seems like it could be a competition. The current trend of the graph on 538 terrifies me",
         null,
         "3",
         "t1_d74ft4z"
        ],
        [
         "1",
         "2016-09-01",
         "1472688001",
         "d74qmze",
         "50juq5",
         "True",
         "OQcjv",
         "politics",
         "t5_2cneq",
         "Hi `alictrmods`. Thank you for participating in /r/Politics. However, [your submission](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/) has been removed for the following reason(s):\n\n* [Off-Topic](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_the_.2Fr.2Fpolitics_on_topic_statement): All submissions to /r/politics need to be explicitly about **current US politics**.\n\n \n\n\n\nIf you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&amp;subject=Question regarding the removal of this submission by /u/xxxxx&amp;message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/?context=10000\\))",
         null,
         "1",
         "t3_50juq5"
        ],
        [
         "2",
         "2016-09-01",
         "1472688002",
         "d74qn03",
         "50kabh",
         "True",
         "mQu7y",
         "The_Donald",
         "t5_38unr",
         "The Mistakes of the Obama...",
         null,
         "1",
         "t3_50kabh"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>body</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>score</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>1472688001</td>\n",
       "      <td>d74qmz3</td>\n",
       "      <td>50grgt</td>\n",
       "      <td>False</td>\n",
       "      <td>krb7H</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>trump seems to be gaining supporters at an inc...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>t1_d74ft4z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>1472688001</td>\n",
       "      <td>d74qmze</td>\n",
       "      <td>50juq5</td>\n",
       "      <td>True</td>\n",
       "      <td>OQcjv</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Hi `alictrmods`. Thank you for participating i...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_50juq5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>1472688002</td>\n",
       "      <td>d74qn03</td>\n",
       "      <td>50kabh</td>\n",
       "      <td>True</td>\n",
       "      <td>mQu7y</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>t5_38unr</td>\n",
       "      <td>The Mistakes of the Obama...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_50kabh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  created_utc comment_id thread_id  is_top_level author  \\\n",
       "0  2016-09-01   1472688001    d74qmz3    50grgt         False  krb7H   \n",
       "1  2016-09-01   1472688001    d74qmze    50juq5          True  OQcjv   \n",
       "2  2016-09-01   1472688002    d74qn03    50kabh          True  mQu7y   \n",
       "\n",
       "    subreddit subreddit_id                                               body  \\\n",
       "0    politics     t5_2cneq  trump seems to be gaining supporters at an inc...   \n",
       "1    politics     t5_2cneq  Hi `alictrmods`. Thank you for participating i...   \n",
       "2  The_Donald     t5_38unr                       The Mistakes of the Obama...   \n",
       "\n",
       "  cleaned_body  score   parent_id  \n",
       "0         None      3  t1_d74ft4z  \n",
       "1         None      1   t3_50juq5  \n",
       "2         None      1   t3_50kabh  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load gold layer (thread-structured comments)\n",
    "# Gold layer has one parquet file per day: 2016-09-01.parquet, 2016-09-02.parquet, etc.\n",
    "\n",
    "print(\"Loading Reddit gold layer...\")\n",
    "\n",
    "# Get all parquet files in gold directory\n",
    "gold_files = sorted(gold_path.glob('*.parquet'))\n",
    "print(f\"Found {len(gold_files)} parquet files\")\n",
    "\n",
    "# Read and concatenate all files\n",
    "dfs = []\n",
    "for file in gold_files:\n",
    "    df_day = read_parquet(file)\n",
    "    dfs.append(df_day)\n",
    "    print(f\"  Loaded {file.name}: {len(df_day):,} comments\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal loaded: {len(df):,} comments\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nSample:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22dda458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation:\n",
      "  Total comments: 8,785,795\n",
      "  Unique threads (thread_id): 510,756\n",
      "  Date range: 2016-09-01 to 2016-10-31\n",
      "  Missing thread_id: 0\n",
      "  Missing body: 0\n"
     ]
    }
   ],
   "source": [
    "# Data validation\n",
    "print(\"Data validation:\")\n",
    "print(f\"  Total comments: {len(df):,}\")\n",
    "print(f\"  Unique threads (thread_id): {df['thread_id'].nunique():,}\")\n",
    "\n",
    "# Convert Unix timestamps to datetime for readable display\n",
    "date_min = pd.to_datetime(df['created_utc'], unit='s').min()\n",
    "date_max = pd.to_datetime(df['created_utc'], unit='s').max()\n",
    "print(f\"  Date range: {date_min.date()} to {date_max.date()}\")\n",
    "\n",
    "print(f\"  Missing thread_id: {df['thread_id'].isna().sum():,}\")\n",
    "print(f\"  Missing body: {df['body'].isna().sum():,}\")\n",
    "\n",
    "# Check for submission metadata\n",
    "if 'submission_title' in df.columns:\n",
    "    print(f\"  Missing submission_title: {df['submission_title'].isna().sum():,}\")\n",
    "if 'submission_selftext' in df.columns:\n",
    "    print(f\"  Missing submission_selftext: {df['submission_selftext'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9b6cb",
   "metadata": {},
   "source": [
    "## 2. Separate Submissions and Comments\n",
    "\n",
    "For each thread:\n",
    "- Identify the submission (initial post) - first comment chronologically per thread_id\n",
    "- Separate regular comments that reply to the submission\n",
    "- This is crucial for providing context during stance detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8afcf83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering empty bodies: 8,785,795 rows\n",
      "Columns: ['date', 'created_utc', 'comment_id', 'thread_id', 'is_top_level', 'author', 'subreddit', 'subreddit_id', 'body', 'cleaned_body', 'score', 'parent_id']\n"
     ]
    }
   ],
   "source": [
    "# Ensure required columns exist\n",
    "required_cols = ['thread_id', 'body', 'created_utc']\n",
    "missing = [col for col in required_cols if col not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Clean text\n",
    "df_clean = df.copy()\n",
    "df_clean['body'] = df_clean['body'].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Filter out empty bodies\n",
    "df_clean = df_clean[df_clean['body'] != '']\n",
    "\n",
    "print(f\"After filtering empty bodies: {len(df_clean):,} rows\")\n",
    "print(f\"Columns: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a424028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying submission posts...\n",
      "Identified 510,756 submission posts\n",
      "\n",
      "Submissions columns: ['thread_id', 'submission_id', 'submission_body', 'submission_time']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_time",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "eec12599-145e-44ea-b13f-ef4ece6d5da2",
       "rows": [
        [
         "0",
         "1nzpxk",
         "d81de5w",
         "Your submission was automatically removed.\n\nWe do not allow posts with little to no content in the body of the post.  Please resubmit your post and include more substance. For instance, give some background information that led to the questions, relevant news that is useful to answer the question, etc.\n\nIf you have any questions about this, please [message the moderators](https://www.reddit.com/message/compose?to=/r/PoliticalDiscussion&amp;subject=link post&amp;message=https://www.reddit.com/r/PoliticalDiscussion/comments/1nzpxk/what_if_we_had_a_televised_conversation_between/).  \nDo not repost this topic without receiving clearance from the moderators.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "1474817641"
        ],
        [
         "1",
         "3la1rr",
         "d90ndc8",
         "Your submission was automatically removed.\n\nWe do not allow posts with little to no content in the body of the post.  Please resubmit your post and include more substance. For instance, give some background information that led to the questions, relevant news that is useful to answer the question, etc.\n\nIf you have any questions about this, please [message the moderators](https://www.reddit.com/message/compose?to=/r/PoliticalDiscussion&amp;subject=link post&amp;message=https://www.reddit.com/r/PoliticalDiscussion/comments/3la1rr/planned_parenthood/).  \nDo not repost this topic without receiving clearance from the moderators.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "1476987946"
        ],
        [
         "2",
         "3o62wk",
         "d7sjcpt",
         "[A reminder for everyone](https://www.reddit.com/r/PoliticalDiscussion/comments/4479er/rules_explanations_and_reminders/). This is a subreddit for genuine discussion:\n\n* Don't post low effort comments like joke threads, memes, slogans, or links without context.\n* Help prevent this subreddit from becoming an echo chamber. Please don't downvote comments with which you disagree.\n* The downvote and report buttons are not disagree buttons.  Please don't use them that way.\n\nViolators will be fed to the bear.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "1474246699"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_body</th>\n",
       "      <th>submission_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1nzpxk</td>\n",
       "      <td>d81de5w</td>\n",
       "      <td>Your submission was automatically removed.\\n\\n...</td>\n",
       "      <td>1474817641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3la1rr</td>\n",
       "      <td>d90ndc8</td>\n",
       "      <td>Your submission was automatically removed.\\n\\n...</td>\n",
       "      <td>1476987946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3o62wk</td>\n",
       "      <td>d7sjcpt</td>\n",
       "      <td>[A reminder for everyone](https://www.reddit.c...</td>\n",
       "      <td>1474246699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  thread_id submission_id                                    submission_body  \\\n",
       "0    1nzpxk       d81de5w  Your submission was automatically removed.\\n\\n...   \n",
       "1    3la1rr       d90ndc8  Your submission was automatically removed.\\n\\n...   \n",
       "2    3o62wk       d7sjcpt  [A reminder for everyone](https://www.reddit.c...   \n",
       "\n",
       "   submission_time  \n",
       "0       1474817641  \n",
       "1       1476987946  \n",
       "2       1474246699  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify submissions (first post per thread chronologically)\n",
    "print(\"Identifying submission posts...\")\n",
    "\n",
    "# Get the earliest comment per thread (this is the submission)\n",
    "# First, get the index of the earliest comment per thread\n",
    "submission_indices = df_clean.groupby('thread_id')['created_utc'].idxmin()\n",
    "\n",
    "# Extract submission rows\n",
    "submissions = df_clean.loc[submission_indices].copy()\n",
    "submissions = submissions.rename(columns={'body': 'submission_body', 'created_utc': 'submission_time'})\n",
    "\n",
    "# Keep only needed columns\n",
    "submission_cols = ['thread_id', 'submission_body', 'submission_time']\n",
    "if 'comment_id' in submissions.columns:\n",
    "    submission_cols.insert(1, 'comment_id')\n",
    "    submissions = submissions.rename(columns={'comment_id': 'submission_id'})\n",
    "    submission_cols[1] = 'submission_id'  # Update in the list too\n",
    "\n",
    "submissions = submissions[submission_cols].reset_index(drop=True)\n",
    "\n",
    "print(f\"Identified {len(submissions):,} submission posts\")\n",
    "print(f\"\\nSubmissions columns: {submissions.columns.tolist()}\")\n",
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36fca357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing thread statistics...\n",
      "Computed stats for 510,756 threads\n",
      "\n",
      "Thread stats columns: ['thread_id', 'thread_start', 'thread_end', 'n_total', 'all_text', 'n_comments']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thread_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "all_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_comments",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "28b3ea4e-907b-4672-a8f6-eb65dde73079",
       "rows": [
        [
         "0",
         "1nzpxk",
         "1474817641",
         "1474817641",
         "1",
         "Your submission was automatically removed.\n\nWe do not allow posts with little to no content in the body of the post.  Please resubmit your post and include more substance. For instance, give some background information that led to the questions, relevant news that is useful to answer the question, etc.\n\nIf you have any questions about this, please [message the moderators](https://www.reddit.com/message/compose?to=/r/PoliticalDiscussion&amp;subject=link post&amp;message=https://www.reddit.com/r/PoliticalDiscussion/comments/1nzpxk/what_if_we_had_a_televised_conversation_between/).  \nDo not repost this topic without receiving clearance from the moderators.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "0"
        ],
        [
         "1",
         "3la1rr",
         "1476987946",
         "1476987946",
         "1",
         "Your submission was automatically removed.\n\nWe do not allow posts with little to no content in the body of the post.  Please resubmit your post and include more substance. For instance, give some background information that led to the questions, relevant news that is useful to answer the question, etc.\n\nIf you have any questions about this, please [message the moderators](https://www.reddit.com/message/compose?to=/r/PoliticalDiscussion&amp;subject=link post&amp;message=https://www.reddit.com/r/PoliticalDiscussion/comments/3la1rr/planned_parenthood/).  \nDo not repost this topic without receiving clearance from the moderators.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "0"
        ],
        [
         "2",
         "3o62wk",
         "1474246699",
         "1474246699",
         "1",
         "[A reminder for everyone](https://www.reddit.com/r/PoliticalDiscussion/comments/4479er/rules_explanations_and_reminders/). This is a subreddit for genuine discussion:\n\n* Don't post low effort comments like joke threads, memes, slogans, or links without context.\n* Help prevent this subreddit from becoming an echo chamber. Please don't downvote comments with which you disagree.\n* The downvote and report buttons are not disagree buttons.  Please don't use them that way.\n\nViolators will be fed to the bear.\n\n---\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PoliticalDiscussion) if you have any questions or concerns.*",
         "0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_start</th>\n",
       "      <th>thread_end</th>\n",
       "      <th>n_total</th>\n",
       "      <th>all_text</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1nzpxk</td>\n",
       "      <td>1474817641</td>\n",
       "      <td>1474817641</td>\n",
       "      <td>1</td>\n",
       "      <td>Your submission was automatically removed.\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3la1rr</td>\n",
       "      <td>1476987946</td>\n",
       "      <td>1476987946</td>\n",
       "      <td>1</td>\n",
       "      <td>Your submission was automatically removed.\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3o62wk</td>\n",
       "      <td>1474246699</td>\n",
       "      <td>1474246699</td>\n",
       "      <td>1</td>\n",
       "      <td>[A reminder for everyone](https://www.reddit.c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  thread_id  thread_start  thread_end  n_total  \\\n",
       "0    1nzpxk    1474817641  1474817641        1   \n",
       "1    3la1rr    1476987946  1476987946        1   \n",
       "2    3o62wk    1474246699  1474246699        1   \n",
       "\n",
       "                                            all_text  n_comments  \n",
       "0  Your submission was automatically removed.\\n\\n...           0  \n",
       "1  Your submission was automatically removed.\\n\\n...           0  \n",
       "2  [A reminder for everyone](https://www.reddit.c...           0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute thread-level statistics\n",
    "print(\"Computing thread statistics...\")\n",
    "\n",
    "# Count comments per thread (including submission)\n",
    "thread_stats = df_clean.groupby('thread_id').agg({\n",
    "    'created_utc': ['min', 'max', 'count'],\n",
    "    'body': lambda x: ' '.join(x)  # Concatenate ALL bodies (submission + comments) for topic modeling\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "thread_stats.columns = ['thread_id', 'thread_start', 'thread_end', 'n_total', 'all_text']\n",
    "\n",
    "# n_comments = n_total - 1 (excluding submission)\n",
    "thread_stats['n_comments'] = thread_stats['n_total'] - 1\n",
    "\n",
    "print(f\"Computed stats for {len(thread_stats):,} threads\")\n",
    "print(f\"\\nThread stats columns: {thread_stats.columns.tolist()}\")\n",
    "thread_stats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a592847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating thread pseudo-documents...\n",
      "Created 510,756 thread pseudo-documents\n",
      "\n",
      "Filtering threads with 0 comments (no replies)...\n",
      "  Before: 510,756 threads\n",
      "  After: 341,692 threads\n",
      "  Removed: 169,064 threads with only submissions\n",
      "\n",
      "✓ Final thread pseudo-documents: 341,692\n",
      "Columns: ['thread_id', 'thread_start', 'thread_end', 'n_comments', 'submission_body', 'pseudodoc_text', 'pseudodoc_length', 'pseudodoc_tokens_approx']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thread_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_comments",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pseudodoc_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pseudodoc_length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pseudodoc_tokens_approx",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2bff1fbf-a435-40b0-afd1-d6db465a1bc8",
       "rows": [
        [
         "7",
         "45fp0h",
         "1477636970",
         "1477637393",
         "2",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "1328",
         "129"
        ],
        [
         "9",
         "468nsf",
         "1477638288",
         "1477638396",
         "2",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "1328",
         "129"
        ],
        [
         "11",
         "46vcvs",
         "1474397005",
         "1474397012",
         "2",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.* Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj59/important_announcement_regarding_the_future_of/)\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/GrassrootsSelect) if you have any questions or concerns.*",
         "1328",
         "129"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_start</th>\n",
       "      <th>thread_end</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>submission_body</th>\n",
       "      <th>pseudodoc_text</th>\n",
       "      <th>pseudodoc_length</th>\n",
       "      <th>pseudodoc_tokens_approx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45fp0h</td>\n",
       "      <td>1477636970</td>\n",
       "      <td>1477637393</td>\n",
       "      <td>2</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>1328</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>468nsf</td>\n",
       "      <td>1477638288</td>\n",
       "      <td>1477638396</td>\n",
       "      <td>2</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>1328</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46vcvs</td>\n",
       "      <td>1474397005</td>\n",
       "      <td>1474397012</td>\n",
       "      <td>2</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>Your post has been removed because /r/Grassroo...</td>\n",
       "      <td>1328</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_id  thread_start  thread_end  n_comments  \\\n",
       "7     45fp0h    1477636970  1477637393           2   \n",
       "9     468nsf    1477638288  1477638396           2   \n",
       "11    46vcvs    1474397005  1474397012           2   \n",
       "\n",
       "                                      submission_body  \\\n",
       "7   Your post has been removed because /r/Grassroo...   \n",
       "9   Your post has been removed because /r/Grassroo...   \n",
       "11  Your post has been removed because /r/Grassroo...   \n",
       "\n",
       "                                       pseudodoc_text  pseudodoc_length  \\\n",
       "7   Your post has been removed because /r/Grassroo...              1328   \n",
       "9   Your post has been removed because /r/Grassroo...              1328   \n",
       "11  Your post has been removed because /r/Grassroo...              1328   \n",
       "\n",
       "    pseudodoc_tokens_approx  \n",
       "7                       129  \n",
       "9                       129  \n",
       "11                      129  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create thread pseudo-documents by merging submissions + stats\n",
    "print(\"Creating thread pseudo-documents...\")\n",
    "\n",
    "# Merge submission text with thread stats\n",
    "thread_pseudodocs = thread_stats.merge(submissions[['thread_id', 'submission_body']], on='thread_id', how='left')\n",
    "\n",
    "# The pseudo-document for topic modeling is: submission + all comments (already in all_text)\n",
    "# But we also keep submission_body separate for later use in stance detection\n",
    "thread_pseudodocs['pseudodoc_text'] = thread_pseudodocs['all_text']\n",
    "\n",
    "# Compute text statistics\n",
    "thread_pseudodocs['pseudodoc_length'] = thread_pseudodocs['pseudodoc_text'].str.len()\n",
    "thread_pseudodocs['pseudodoc_tokens_approx'] = thread_pseudodocs['pseudodoc_text'].str.split().str.len()\n",
    "\n",
    "# Drop the temporary all_text column\n",
    "thread_pseudodocs = thread_pseudodocs.drop(columns=['all_text', 'n_total'])\n",
    "\n",
    "print(f\"Created {len(thread_pseudodocs):,} thread pseudo-documents\")\n",
    "\n",
    "# Filter out threads with 0 comments (no interaction = no polarization)\n",
    "print(f\"\\nFiltering threads with 0 comments (no replies)...\")\n",
    "print(f\"  Before: {len(thread_pseudodocs):,} threads\")\n",
    "thread_pseudodocs = thread_pseudodocs[thread_pseudodocs['n_comments'] > 0].copy()\n",
    "print(f\"  After: {len(thread_pseudodocs):,} threads\")\n",
    "print(f\"  Removed: {len(thread_stats) - len(thread_pseudodocs):,} threads with only submissions\")\n",
    "\n",
    "print(f\"\\n✓ Final thread pseudo-documents: {len(thread_pseudodocs):,}\")\n",
    "print(f\"Columns: {thread_pseudodocs.columns.tolist()}\")\n",
    "thread_pseudodocs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21656d59",
   "metadata": {},
   "source": [
    "## 3. Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5788aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "THREAD STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total threads: 341,692\n",
      "Total submissions: 510,756\n",
      "\n",
      "Metric                               Mean     Median        Min        Max\n",
      "----------------------------------------------------------------------\n",
      "Comments per thread                  24.2          4          1      24156\n",
      "Pseudo-doc characters                5472       1059         18    3883085\n",
      "Pseudo-doc tokens (approx)            907        166          2     660136\n"
     ]
    }
   ],
   "source": [
    "# Thread statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"THREAD STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal threads: {len(thread_pseudodocs):,}\")\n",
    "print(f\"Total submissions: {len(submissions):,}\")\n",
    "\n",
    "print(f\"\\n{'Metric':<30} {'Mean':>10} {'Median':>10} {'Min':>10} {'Max':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Comments per thread (excluding submission)\n",
    "stats = thread_pseudodocs['n_comments'].describe()\n",
    "print(f\"{'Comments per thread':<30} {stats['mean']:>10.1f} {stats['50%']:>10.0f} {stats['min']:>10.0f} {stats['max']:>10.0f}\")\n",
    "\n",
    "# Pseudo-document length\n",
    "stats = thread_pseudodocs['pseudodoc_length'].describe()\n",
    "print(f\"{'Pseudo-doc characters':<30} {stats['mean']:>10.0f} {stats['50%']:>10.0f} {stats['min']:>10.0f} {stats['max']:>10.0f}\")\n",
    "\n",
    "# Pseudo-document tokens\n",
    "stats = thread_pseudodocs['pseudodoc_tokens_approx'].describe()\n",
    "print(f\"{'Pseudo-doc tokens (approx)':<30} {stats['mean']:>10.0f} {stats['50%']:>10.0f} {stats['min']:>10.0f} {stats['max']:>10.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f97ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEMPORAL DISTRIBUTION (SUBMISSIONS)\n",
      "============================================================\n",
      "\n",
      "Submission dates: 2016-09-01 to 2016-10-31\n",
      "Mean submissions/day: 8373\n",
      "Median submissions/day: 7874\n",
      "\n",
      "Days with most activity:\n",
      "submission_date\n",
      "2016-10-10    13564\n",
      "2016-10-20    13523\n",
      "2016-10-28    12699\n",
      "2016-10-18    12133\n",
      "2016-10-31    12075\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Temporal distribution of submissions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEMPORAL DISTRIBUTION (SUBMISSIONS)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert submission times to datetime\n",
    "submissions_temporal = submissions.copy()\n",
    "submissions_temporal['submission_date'] = pd.to_datetime(\n",
    "    submissions_temporal['submission_time'], unit='s'\n",
    ").dt.date\n",
    "\n",
    "# Daily counts\n",
    "daily_counts = submissions_temporal.groupby('submission_date').size()\n",
    "\n",
    "print(f\"\\nSubmission dates: {daily_counts.index.min()} to {daily_counts.index.max()}\")\n",
    "print(f\"Mean submissions/day: {daily_counts.mean():.0f}\")\n",
    "print(f\"Median submissions/day: {daily_counts.median():.0f}\")\n",
    "print(f\"\\nDays with most activity:\")\n",
    "print(daily_counts.nlargest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4063de6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE PSEUDO-DOCUMENTS\n",
      "============================================================\n",
      "\n",
      "Thread 45fp0h:\n",
      "  Comments: 2\n",
      "  Length: 1,328 chars, ~129 tokens\n",
      "  Submission preview: Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https...\n",
      "  Full text preview: Your post has been removed because /r/GrassrootsSelect has offically moved to /r/Political_Revolution. You can read the announcement post [here](https://www.reddit.com/r/GrassrootsSelect/comments/4rjj...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Thread 566soa:\n",
      "  Comments: 12\n",
      "  Length: 1,232 chars, ~206 tokens\n",
      "  Submission preview: Ok I'll also donate $5...\n",
      "  Full text preview: Ok I'll also donate $5 Ill donate my brothers kidney. I donated my lake house I knocked the chicken nuggets out of my mom's hands and into Bernie's Get a sticker! And new pins! Sounds like someone's g...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Thread 5afyzw:\n",
      "  Comments: 1\n",
      "  Length: 1,782 chars, ~232 tokens\n",
      "  Submission preview: As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)\n",
      "\n",
      "* Do not call othe...\n",
      "  Full text preview: As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)\n",
      "\n",
      "* Do not call other users trolls, morons, children, or anything else...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample pseudo-documents\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PSEUDO-DOCUMENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i in [0, len(thread_pseudodocs)//2, -1]:\n",
    "    row = thread_pseudodocs.iloc[i]\n",
    "    print(f\"\\nThread {row['thread_id']}:\")\n",
    "    print(f\"  Comments: {row['n_comments']}\")\n",
    "    print(f\"  Length: {row['pseudodoc_length']:,} chars, ~{row['pseudodoc_tokens_approx']:,} tokens\")\n",
    "    print(f\"  Submission preview: {row['submission_body'][:150]}...\")\n",
    "    print(f\"  Full text preview: {row['pseudodoc_text'][:200]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4785f1",
   "metadata": {},
   "source": [
    "## 4. Create Comment and Thread Metadata\n",
    "\n",
    "Create two tables:\n",
    "1. **comment_thread_map**: All comments (submissions + replies) with full context for stance detection\n",
    "\n",
    "2. **thread_metadata**: Thread-level statisticsOnly include comments from threads with n_comments > 0 (threads with actual interaction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d168a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comment-to-thread mapping...\n",
      "Valid threads (n_comments > 0): 341,692\n",
      "Comments from valid threads: 8,616,731\n",
      "✓ Created mapping for 8,616,731 comments (submissions + replies)\n",
      "  Submissions: 341,692\n",
      "  Replies: 8,275,039\n",
      "\n",
      "Columns: ['comment_id', 'comment_body', 'created_utc', 'subreddit_id', 'subreddit', 'author', 'parent_id', 'thread_id', 'is_top_level', 'submission_id', 'submission_body', 'submission_time']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "comment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_utc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subreddit_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parent_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_top_level",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "submission_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_time",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "549c19c3-3c12-440b-a6f2-e30558bad512",
       "rows": [
        [
         "0",
         "d74qmz3",
         "trump seems to be gaining supporters at an increasing rate. I remember when he had single-digit chances of winning. Now it almost seems like it could be a competition. The current trend of the graph on 538 terrifies me",
         "1472688001",
         "t5_2cneq",
         "politics",
         "krb7H",
         "t1_d74ft4z",
         "50grgt",
         "False",
         "d74qmz3",
         "trump seems to be gaining supporters at an increasing rate. I remember when he had single-digit chances of winning. Now it almost seems like it could be a competition. The current trend of the graph on 538 terrifies me",
         "1472688001"
        ],
        [
         "1",
         "d74qmze",
         "Hi `alictrmods`. Thank you for participating in /r/Politics. However, [your submission](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/) has been removed for the following reason(s):\n\n* [Off-Topic](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_the_.2Fr.2Fpolitics_on_topic_statement): All submissions to /r/politics need to be explicitly about **current US politics**.\n\n \n\n\n\nIf you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&amp;subject=Question regarding the removal of this submission by /u/xxxxx&amp;message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/?context=10000\\))",
         "1472688001",
         "t5_2cneq",
         "politics",
         "OQcjv",
         "t3_50juq5",
         "50juq5",
         "True",
         "d74qmze",
         "Hi `alictrmods`. Thank you for participating in /r/Politics. However, [your submission](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/) has been removed for the following reason(s):\n\n* [Off-Topic](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_the_.2Fr.2Fpolitics_on_topic_statement): All submissions to /r/politics need to be explicitly about **current US politics**.\n\n \n\n\n\nIf you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&amp;subject=Question regarding the removal of this submission by /u/xxxxx&amp;message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/50juq5/press_ignores_kaepernicks_hillary_for_prison/?context=10000\\))",
         "1472688001"
        ],
        [
         "2",
         "d74qn03",
         "The Mistakes of the Obama...",
         "1472688002",
         "t5_38unr",
         "The_Donald",
         "mQu7y",
         "t3_50kabh",
         "50kabh",
         "True",
         "d74qn03",
         "The Mistakes of the Obama...",
         "1472688002"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>is_top_level</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>submission_body</th>\n",
       "      <th>submission_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d74qmz3</td>\n",
       "      <td>trump seems to be gaining supporters at an inc...</td>\n",
       "      <td>1472688001</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>politics</td>\n",
       "      <td>krb7H</td>\n",
       "      <td>t1_d74ft4z</td>\n",
       "      <td>50grgt</td>\n",
       "      <td>False</td>\n",
       "      <td>d74qmz3</td>\n",
       "      <td>trump seems to be gaining supporters at an inc...</td>\n",
       "      <td>1472688001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d74qmze</td>\n",
       "      <td>Hi `alictrmods`. Thank you for participating i...</td>\n",
       "      <td>1472688001</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>politics</td>\n",
       "      <td>OQcjv</td>\n",
       "      <td>t3_50juq5</td>\n",
       "      <td>50juq5</td>\n",
       "      <td>True</td>\n",
       "      <td>d74qmze</td>\n",
       "      <td>Hi `alictrmods`. Thank you for participating i...</td>\n",
       "      <td>1472688001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d74qn03</td>\n",
       "      <td>The Mistakes of the Obama...</td>\n",
       "      <td>1472688002</td>\n",
       "      <td>t5_38unr</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>mQu7y</td>\n",
       "      <td>t3_50kabh</td>\n",
       "      <td>50kabh</td>\n",
       "      <td>True</td>\n",
       "      <td>d74qn03</td>\n",
       "      <td>The Mistakes of the Obama...</td>\n",
       "      <td>1472688002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                       comment_body  created_utc  \\\n",
       "0    d74qmz3  trump seems to be gaining supporters at an inc...   1472688001   \n",
       "1    d74qmze  Hi `alictrmods`. Thank you for participating i...   1472688001   \n",
       "2    d74qn03                       The Mistakes of the Obama...   1472688002   \n",
       "\n",
       "  subreddit_id   subreddit author   parent_id thread_id  is_top_level  \\\n",
       "0     t5_2cneq    politics  krb7H  t1_d74ft4z    50grgt         False   \n",
       "1     t5_2cneq    politics  OQcjv   t3_50juq5    50juq5          True   \n",
       "2     t5_38unr  The_Donald  mQu7y   t3_50kabh    50kabh          True   \n",
       "\n",
       "  submission_id                                    submission_body  \\\n",
       "0       d74qmz3  trump seems to be gaining supporters at an inc...   \n",
       "1       d74qmze  Hi `alictrmods`. Thank you for participating i...   \n",
       "2       d74qn03                       The Mistakes of the Obama...   \n",
       "\n",
       "   submission_time  \n",
       "0       1472688001  \n",
       "1       1472688001  \n",
       "2       1472688002  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comprehensive comment-to-thread mapping\n",
    "print(\"Creating comment-to-thread mapping...\")\n",
    "\n",
    "# Get threads that have interaction (n_comments > 0)\n",
    "valid_threads = set(thread_pseudodocs['thread_id'].values)\n",
    "print(f\"Valid threads (n_comments > 0): {len(valid_threads):,}\")\n",
    "\n",
    "# Filter df_clean to only include comments from valid threads\n",
    "df_filtered = df_clean[df_clean['thread_id'].isin(valid_threads)].copy()\n",
    "print(f\"Comments from valid threads: {len(df_filtered):,}\")\n",
    "\n",
    "# Select all available columns\n",
    "comment_cols = ['comment_id', 'thread_id', 'created_utc', 'body', 'is_top_level', \n",
    "                'author', 'subreddit', 'subreddit_id', 'parent_id']\n",
    "available_cols = [col for col in comment_cols if col in df_filtered.columns]\n",
    "\n",
    "comment_map = df_filtered[available_cols].copy()\n",
    "comment_map = comment_map.rename(columns={'body': 'comment_body'})\n",
    "\n",
    "# Merge with submission information\n",
    "submission_info = submissions[['thread_id', 'submission_id', 'submission_body', 'submission_time']].copy()\n",
    "comment_map = comment_map.merge(submission_info, on='thread_id', how='left')\n",
    "\n",
    "# Reorder columns for better readability\n",
    "col_order = ['comment_id', 'comment_body', 'created_utc', 'subreddit_id', 'subreddit', \n",
    "             'author', 'parent_id', 'thread_id', 'is_top_level', 'submission_id', \n",
    "             'submission_body', 'submission_time']\n",
    "final_cols = [col for col in col_order if col in comment_map.columns]\n",
    "comment_map = comment_map[final_cols]\n",
    "\n",
    "print(f\"✓ Created mapping for {len(comment_map):,} comments (submissions + replies)\")\n",
    "print(f\"  Submissions: {comment_map['comment_id'].isin(submissions['submission_id']).sum():,}\")\n",
    "print(f\"  Replies: {(~comment_map['comment_id'].isin(submissions['submission_id'])).sum():,}\")\n",
    "print(f\"\\nColumns: {comment_map.columns.tolist()}\")\n",
    "comment_map.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2a700db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating thread metadata...\n",
      "✓ Created metadata for 341,692 threads\n",
      "\n",
      "Columns: ['thread_id', 'thread_start', 'thread_end', 'n_comments']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "thread_start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thread_end",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_comments",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c1c702a3-f6a6-46c5-8d76-78289cda7104",
       "rows": [
        [
         "7",
         "45fp0h",
         "1477636970",
         "1477637393",
         "2"
        ],
        [
         "9",
         "468nsf",
         "1477638288",
         "1477638396",
         "2"
        ],
        [
         "11",
         "46vcvs",
         "1474397005",
         "1474397012",
         "2"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>thread_start</th>\n",
       "      <th>thread_end</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45fp0h</td>\n",
       "      <td>1477636970</td>\n",
       "      <td>1477637393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>468nsf</td>\n",
       "      <td>1477638288</td>\n",
       "      <td>1477638396</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>46vcvs</td>\n",
       "      <td>1474397005</td>\n",
       "      <td>1474397012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_id  thread_start  thread_end  n_comments\n",
       "7     45fp0h    1477636970  1477637393           2\n",
       "9     468nsf    1477638288  1477638396           2\n",
       "11    46vcvs    1474397005  1474397012           2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create thread metadata table\n",
    "print(\"\\nCreating thread metadata...\")\n",
    "\n",
    "thread_metadata = thread_pseudodocs[['thread_id', 'thread_start', 'thread_end', 'n_comments']].copy()\n",
    "\n",
    "print(f\"✓ Created metadata for {len(thread_metadata):,} threads\")\n",
    "print(f\"\\nColumns: {thread_metadata.columns.tolist()}\")\n",
    "thread_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c2d246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA QUALITY VERIFICATION\n",
      "============================================================\n",
      "\n",
      "Comment breakdown:\n",
      "  Total comments: 8,616,731\n",
      "  Submissions (comment_id == submission_id): 341,692\n",
      "  Replies (comment_id != submission_id): 8,275,039\n",
      "\n",
      "Sample thread verification (thread_id: 4yfa7i):\n",
      "  n_comments from metadata: 1\n",
      "  Total comments in map: 2\n",
      "  Submission: 1\n",
      "  Replies: 1\n",
      "\n",
      "First 3 comments from this thread:\n",
      "  [SUBMISSION] d76wu8m: But you're talking apples and oranges.\n",
      "\n",
      "The Canadian banks discussed there are consumer deposit banks -- that's where the 7% capital reserve applies.\n",
      "\n",
      "The banks in the US that got hit in the crisis were investment banks, for the most part. If you're looking at TD Bank, you should be comparing WF, Citi, Chase, BoA, etc. but when you say the \"banks that crashed the economy\", you're talking about Lehman, Bear, Goldman, etc. They are completely different types of institutions.\n",
      "\n",
      "We don't have nearly as many investment banks, but regulation is very limited....\n",
      "    Submission context: But you're talking apples and oranges.\n",
      "\n",
      "The Canadian banks discussed there are consumer deposit banks -- that's where the 7% capital reserve applies.\n",
      "\n",
      "The banks in the US that got hit in the crisis were investment banks, for the most part. If you're looking at TD Bank, you should be comparing WF, Citi, Chase, BoA, etc. but when you say the \"banks that crashed the economy\", you're talking about Lehman, Bear, Goldman, etc. They are completely different types of institutions.\n",
      "\n",
      "We don't have nearly as many investment banks, but regulation is very limited....\n",
      "  [REPLY] d76y5pt: &gt; The Canadian banks discussed there are consumer deposit banks -- that's where the 7% capital reserve applies.\n",
      "\n",
      "I think you probably know far more about the structure of the Canadian banking industry than I do, but in Canada, don't the Big 6 banks dominate investment banking as well as retail banking? This [2012 Globe and Mail article](http://www.theglobeandmail.com/report-on-business/streetwise/four-canadian-banks-make-top-25-for-investment-banking-fees/article4099063/) cites the investment banking operations of RBC, Bank of Montreal, TD, and Scotia as making it onto the list of top 25 investment banks (by investment banking fees).\n",
      "\n",
      "[Why the Canadian investment banks largely avoided the painful global restructuring](http://www.hamilton-capital.com/why-the-canadian-investment-banks-largely-avoided-the-painful-global-restructuring/) suggests that regulation played a role:\n",
      "\n",
      "&gt; Relative to global investment banks, Canadian investment banks entered the crisis with materially lower leverage than their global investment banking peers. **As a subsidiary of a regulated commercial bank, Canadian investment banks were/are required to operate under the parent bank's total bank capital rules which include a limit for assets-to-capital**. This meant the sector's business model is designed to generate returns on a higher capital base. As a result, these subsidiaries experienced lower dilution to their returns on capital than their global peers (although the Canadian banks did seek to increase capital levels, post crisis)....\n",
      "    Submission context: But you're talking apples and oranges.\n",
      "\n",
      "The Canadian banks discussed there are consumer deposit banks -- that's where the 7% capital reserve applies.\n",
      "\n",
      "The banks in the US that got hit in the crisis were investment banks, for the most part. If you're looking at TD Bank, you should be comparing WF, Citi, Chase, BoA, etc. but when you say the \"banks that crashed the economy\", you're talking about Lehman, Bear, Goldman, etc. They are completely different types of institutions.\n",
      "\n",
      "We don't have nearly as many investment banks, but regulation is very limited....\n"
     ]
    }
   ],
   "source": [
    "# Verify data quality\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check that submissions and replies are properly separated\n",
    "print(f\"\\nComment breakdown:\")\n",
    "print(f\"  Total comments: {len(comment_map):,}\")\n",
    "print(f\"  Submissions (comment_id == submission_id): {(comment_map['comment_id'] == comment_map['submission_id']).sum():,}\")\n",
    "print(f\"  Replies (comment_id != submission_id): {(comment_map['comment_id'] != comment_map['submission_id']).sum():,}\")\n",
    "\n",
    "# Sample a thread to verify structure\n",
    "sample_thread = thread_pseudodocs.iloc[1000]\n",
    "print(f\"\\nSample thread verification (thread_id: {sample_thread['thread_id']}):\")\n",
    "print(f\"  n_comments from metadata: {sample_thread['n_comments']}\")\n",
    "\n",
    "# Get all comments for this thread\n",
    "thread_comments = comment_map[comment_map['thread_id'] == sample_thread['thread_id']].sort_values('created_utc')\n",
    "print(f\"  Total comments in map: {len(thread_comments)}\")\n",
    "print(f\"  Submission: {(thread_comments['comment_id'] == thread_comments['submission_id']).sum()}\")\n",
    "print(f\"  Replies: {(thread_comments['comment_id'] != thread_comments['submission_id']).sum()}\")\n",
    "\n",
    "# Show first few comments to verify structure\n",
    "print(f\"\\nFirst 3 comments from this thread:\")\n",
    "for idx, row in thread_comments.head(3).iterrows():\n",
    "    is_submission = row['comment_id'] == row['submission_id']\n",
    "    print(f\"  {'[SUBMISSION]' if is_submission else '[REPLY]'} {row['comment_id']}: {row['comment_body']}...\")\n",
    "    print(f\"    Submission context: {row['submission_body']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36176579",
   "metadata": {},
   "source": [
    "## 5. Save Outputs\n",
    "\n",
    "Save three key outputs:\n",
    "1. **thread_pseudodocs.parquet**: Thread-level pseudo-documents (submission + all comments) for topic modeling\n",
    "2. **thread_metadata.parquet**: Thread-level statistics (thread_id, start, end, n_comments)\n",
    "3. **comment_thread_map.parquet**: All comments with full context for stance detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459ebb6",
   "metadata": {},
   "source": [
    "## 5. Save Outputs\n",
    "\n",
    "Save three key outputs:\n",
    "1. **thread_pseudodocs.parquet**: Thread-level pseudo-documents (submission + all comments) for topic modeling\n",
    "2. **thread_metadata.parquet**: Thread-level statistics (thread_id, start, end, n_comments)\n",
    "3. **comment_thread_map.parquet**: All comments with full context for stance detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcfb5a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving thread pseudo-documents...\n",
      "✓ Wrote 341,692 rows to thread_pseudodocs.parquet (1091.7 MB)\n",
      "✓ Saved 341,692 thread pseudo-documents\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/thread_pseudodocs.parquet\n",
      "\n",
      "Saving thread metadata...\n",
      "✓ Wrote 341,692 rows to thread_metadata.parquet (5.7 MB)\n",
      "✓ Saved 341,692 thread metadata records\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/thread_metadata.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save thread pseudo-documents\n",
    "print(\"Saving thread pseudo-documents...\")\n",
    "thread_output = output_path / 'thread_pseudodocs.parquet'\n",
    "write_parquet(thread_pseudodocs, thread_output)\n",
    "print(f\"✓ Saved {len(thread_pseudodocs):,} thread pseudo-documents\")\n",
    "print(f\"  Location: {thread_output}\")\n",
    "\n",
    "# Save thread metadata\n",
    "print(\"\\nSaving thread metadata...\")\n",
    "metadata_output = output_path / 'thread_metadata.parquet'\n",
    "write_parquet(thread_metadata, metadata_output)\n",
    "print(f\"✓ Saved {len(thread_metadata):,} thread metadata records\")\n",
    "print(f\"  Location: {metadata_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9815ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving comment-thread mapping...\n",
      "✓ Wrote 8,616,731 rows to comment_thread_map.parquet (2147.3 MB)\n",
      "✓ Saved 8,616,731 comments (submissions + replies)\n",
      "  Location: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/comment_thread_map.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save comment-thread mapping with full context\n",
    "print(\"\\nSaving comment-thread mapping...\")\n",
    "comment_output = output_path / 'comment_thread_map.parquet'\n",
    "write_parquet(comment_map, comment_output)\n",
    "print(f\"✓ Saved {len(comment_map):,} comments (submissions + replies)\")\n",
    "print(f\"  Location: {comment_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974215fc",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "Generate metadata for this processing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f617516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUN SUMMARY\n",
      "============================================================\n",
      "\n",
      "Notebook: 14_reddit_corpus_prep_topics\n",
      "Timestamp: 2025-12-19T14:50:01.648488\n",
      "\n",
      "Inputs:\n",
      "  Gold layer: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/02_gold/reddit\n",
      "  Files: 61\n",
      "  Comments (raw): 8,785,795\n",
      "\n",
      "Outputs:\n",
      "  Threads: 341,692\n",
      "  Submissions: 510,756\n",
      "  Comments (total): 8,616,731\n",
      "\n",
      "Summary saved to: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/run_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Create summary metadata\n",
    "summary = {\n",
    "    'notebook': '14_reddit_corpus_prep_topics',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'inputs': {\n",
    "        'gold_layer': str(gold_path),\n",
    "        'n_files': len(gold_files),\n",
    "        'n_comments_raw': len(df)\n",
    "    },\n",
    "    'outputs': {\n",
    "        'thread_pseudodocs': str(thread_output),\n",
    "        'comment_thread_map': str(comment_output),\n",
    "        'n_threads': len(thread_pseudodocs),\n",
    "        'n_submissions': len(submissions),\n",
    "        'n_comments_total': len(comment_map)\n",
    "    },\n",
    "    'statistics': {\n",
    "        'comments_per_thread': {\n",
    "            'mean': float(thread_pseudodocs['n_comments'].mean()),\n",
    "            'median': float(thread_pseudodocs['n_comments'].median()),\n",
    "            'min': int(thread_pseudodocs['n_comments'].min()),\n",
    "            'max': int(thread_pseudodocs['n_comments'].max())\n",
    "        },\n",
    "        'pseudodoc_length_chars': {\n",
    "            'mean': float(thread_pseudodocs['pseudodoc_length'].mean()),\n",
    "            'median': float(thread_pseudodocs['pseudodoc_length'].median()),\n",
    "            'min': int(thread_pseudodocs['pseudodoc_length'].min()),\n",
    "            'max': int(thread_pseudodocs['pseudodoc_length'].max())\n",
    "        },\n",
    "        'pseudodoc_tokens_approx': {\n",
    "            'mean': float(thread_pseudodocs['pseudodoc_tokens_approx'].mean()),\n",
    "            'median': float(thread_pseudodocs['pseudodoc_tokens_approx'].median())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary to file\n",
    "summary_file = output_path / 'run_metadata.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RUN SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNotebook: {summary['notebook']}\")\n",
    "print(f\"Timestamp: {summary['timestamp']}\")\n",
    "print(f\"\\nInputs:\")\n",
    "print(f\"  Gold layer: {summary['inputs']['gold_layer']}\")\n",
    "print(f\"  Files: {summary['inputs']['n_files']}\")\n",
    "print(f\"  Comments (raw): {summary['inputs']['n_comments_raw']:,}\")\n",
    "print(f\"\\nOutputs:\")\n",
    "print(f\"  Threads: {summary['outputs']['n_threads']:,}\")\n",
    "print(f\"  Submissions: {summary['outputs']['n_submissions']:,}\")\n",
    "print(f\"  Comments (total): {summary['outputs']['n_comments_total']:,}\")\n",
    "print(f\"\\nSummary saved to: {summary_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
