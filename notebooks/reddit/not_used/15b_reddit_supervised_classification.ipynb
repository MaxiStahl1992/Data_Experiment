{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c425a5",
   "metadata": {},
   "source": [
    "# NOT SELECTED DUE TOLONG EXECUTION TIME -> 24h plus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3e6596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.0\n",
      "CUDA available: False\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad3aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon MPS\n",
      "\n",
      "Configuration:\n",
      "  Data directory: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/02_topics/03_gold/reddit\n",
      "  Model: facebook/bart-large-mnli\n",
      "  Batch size: 16\n",
      "  Device: 0\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path('/Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment')\n",
    "INPUT_DIR = BASE_DIR / 'data' / '01_corpus' / '03_qa' / 'reddit'\n",
    "DATA_DIR = BASE_DIR / 'data' / '02_topics' / '03_gold' / 'reddit'\n",
    "OUTPUT_DIR = DATA_DIR\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = 'facebook/bart-large-mnli'\n",
    "BATCH_SIZE = 16  # Process 16 documents at a time\n",
    "USE_GPU = True   # Use MPS (Apple Silicon) or CUDA if available\n",
    "\n",
    "# Determine device\n",
    "if USE_GPU:\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0  # CUDA device\n",
    "        print(\"Using CUDA GPU\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 0  # MPS will be handled by transformers\n",
    "        print(\"Using Apple Silicon MPS\")\n",
    "    else:\n",
    "        device = -1  # CPU\n",
    "        print(\"No GPU available, using CPU\")\n",
    "else:\n",
    "    device = -1\n",
    "    print(\"Using CPU (GPU disabled)\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Data directory: {DATA_DIR}\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c64d1",
   "metadata": {},
   "source": [
    "## Define Political Topic Taxonomy\n",
    "\n",
    "20 political topics adapted from the Comparative Agendas Project (CAP) framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49159e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Political Topic Taxonomy (20 Topics) ===\n",
      "\n",
      "Source: Comparative Agendas Project (CAP)\n",
      "\n",
      " 0. Elections & Voting\n",
      "    Electoral processes, campaigns, voting rights, electoral reform, and voter registration\n",
      "\n",
      " 1. Presidential Politics\n",
      "    Presidential actions, administration policies, executive orders, and White House activities\n",
      "\n",
      " 2. Congress & Legislation\n",
      "    Congressional activities, legislative processes, lawmakers, and parliamentary procedures\n",
      "\n",
      " 3. Healthcare Policy\n",
      "    Health insurance, Affordable Care Act, medical costs, public health, and healthcare reform\n",
      "\n",
      " 4. Immigration & Borders\n",
      "    Immigration policy, border security, refugee issues, deportation, and asylum\n",
      "\n",
      " 5. Economy & Employment\n",
      "    Jobs, unemployment, wages, labor issues, economic growth, and workplace regulations\n",
      "\n",
      " 6. Budget & Taxation\n",
      "    Federal budget, taxes, government spending, deficits, and fiscal policy\n",
      "\n",
      " 7. Education Policy\n",
      "    Schools, universities, student loans, education reform, and academic issues\n",
      "\n",
      " 8. Criminal Justice\n",
      "    Crime, policing, prisons, law enforcement, justice system, and criminal sentencing\n",
      "\n",
      " 9. Gun Rights & Control\n",
      "    Second Amendment, gun violence, firearms regulation, and gun ownership\n",
      "\n",
      "10. Environment & Climate\n",
      "    Climate change, EPA regulations, pollution, conservation, and environmental protection\n",
      "\n",
      "11. Energy Policy\n",
      "    Oil, gas, renewable energy, energy independence, and energy regulations\n",
      "\n",
      "12. Foreign Policy & Diplomacy\n",
      "    International relations, diplomacy, global issues, and foreign affairs\n",
      "\n",
      "13. Defense & Military\n",
      "    Military operations, veterans, defense spending, armed forces, and national security\n",
      "\n",
      "14. Trade Policy\n",
      "    International trade, tariffs, trade agreements, imports, and exports\n",
      "\n",
      "15. Social Issues\n",
      "    Abortion, LGBTQ rights, religious freedom, family values, and moral issues\n",
      "\n",
      "16. Civil Rights & Discrimination\n",
      "    Racial justice, discrimination, equality issues, and civil rights movements\n",
      "\n",
      "17. Media & Free Speech\n",
      "    Press freedom, censorship, media bias, First Amendment, and journalism\n",
      "\n",
      "18. Technology & Privacy\n",
      "    Tech regulation, surveillance, data privacy, cybersecurity, and digital rights\n",
      "\n",
      "19. Infrastructure\n",
      "    Roads, bridges, public transit, infrastructure investment, and transportation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define 20 political topics with natural language descriptions\n",
    "# Based on Comparative Agendas Project (CAP) codebook\n",
    "\n",
    "POLITICAL_TOPICS = {\n",
    "    0: {\n",
    "        'label': 'Elections & Voting',\n",
    "        'description': 'Electoral processes, campaigns, voting rights, electoral reform, and voter registration'\n",
    "    },\n",
    "    1: {\n",
    "        'label': 'Presidential Politics',\n",
    "        'description': 'Presidential actions, administration policies, executive orders, and White House activities'\n",
    "    },\n",
    "    2: {\n",
    "        'label': 'Congress & Legislation',\n",
    "        'description': 'Congressional activities, legislative processes, lawmakers, and parliamentary procedures'\n",
    "    },\n",
    "    3: {\n",
    "        'label': 'Healthcare Policy',\n",
    "        'description': 'Health insurance, Affordable Care Act, medical costs, public health, and healthcare reform'\n",
    "    },\n",
    "    4: {\n",
    "        'label': 'Immigration & Borders',\n",
    "        'description': 'Immigration policy, border security, refugee issues, deportation, and asylum'\n",
    "    },\n",
    "    5: {\n",
    "        'label': 'Economy & Employment',\n",
    "        'description': 'Jobs, unemployment, wages, labor issues, economic growth, and workplace regulations'\n",
    "    },\n",
    "    6: {\n",
    "        'label': 'Budget & Taxation',\n",
    "        'description': 'Federal budget, taxes, government spending, deficits, and fiscal policy'\n",
    "    },\n",
    "    7: {\n",
    "        'label': 'Education Policy',\n",
    "        'description': 'Schools, universities, student loans, education reform, and academic issues'\n",
    "    },\n",
    "    8: {\n",
    "        'label': 'Criminal Justice',\n",
    "        'description': 'Crime, policing, prisons, law enforcement, justice system, and criminal sentencing'\n",
    "    },\n",
    "    9: {\n",
    "        'label': 'Gun Rights & Control',\n",
    "        'description': 'Second Amendment, gun violence, firearms regulation, and gun ownership'\n",
    "    },\n",
    "    10: {\n",
    "        'label': 'Environment & Climate',\n",
    "        'description': 'Climate change, EPA regulations, pollution, conservation, and environmental protection'\n",
    "    },\n",
    "    11: {\n",
    "        'label': 'Energy Policy',\n",
    "        'description': 'Oil, gas, renewable energy, energy independence, and energy regulations'\n",
    "    },\n",
    "    12: {\n",
    "        'label': 'Foreign Policy & Diplomacy',\n",
    "        'description': 'International relations, diplomacy, global issues, and foreign affairs'\n",
    "    },\n",
    "    13: {\n",
    "        'label': 'Defense & Military',\n",
    "        'description': 'Military operations, veterans, defense spending, armed forces, and national security'\n",
    "    },\n",
    "    14: {\n",
    "        'label': 'Trade Policy',\n",
    "        'description': 'International trade, tariffs, trade agreements, imports, and exports'\n",
    "    },\n",
    "    15: {\n",
    "        'label': 'Social Issues',\n",
    "        'description': 'Abortion, LGBTQ rights, religious freedom, family values, and moral issues'\n",
    "    },\n",
    "    16: {\n",
    "        'label': 'Civil Rights & Discrimination',\n",
    "        'description': 'Racial justice, discrimination, equality issues, and civil rights movements'\n",
    "    },\n",
    "    17: {\n",
    "        'label': 'Media & Free Speech',\n",
    "        'description': 'Press freedom, censorship, media bias, First Amendment, and journalism'\n",
    "    },\n",
    "    18: {\n",
    "        'label': 'Technology & Privacy',\n",
    "        'description': 'Tech regulation, surveillance, data privacy, cybersecurity, and digital rights'\n",
    "    },\n",
    "    19: {\n",
    "        'label': 'Infrastructure',\n",
    "        'description': 'Roads, bridges, public transit, infrastructure investment, and transportation'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Extract labels and descriptions for classification\n",
    "topic_labels = [POLITICAL_TOPICS[i]['label'] for i in range(20)]\n",
    "topic_descriptions = [POLITICAL_TOPICS[i]['description'] for i in range(20)]\n",
    "\n",
    "print(\"\\n=== Political Topic Taxonomy (20 Topics) ===\")\n",
    "print(\"\\nSource: Comparative Agendas Project (CAP)\\n\")\n",
    "for topic_id, topic_info in POLITICAL_TOPICS.items():\n",
    "    print(f\"{topic_id:2d}. {topic_info['label']}\")\n",
    "    print(f\"    {topic_info['description']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b331b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75e4d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/01_corpus/03_qa/reddit/thread_pseudodocs.parquet\n",
      "\n",
      "Data loaded:\n",
      "  Total documents: 433,973\n",
      "  Date range: 1472688024 to 1477954796\n",
      "  Columns: ['submission_id', 'title', 'selftext', 'n_comments', 'pseudodoc_text', 'pseudodoc_length', 'pseudodoc_tokens_approx', 'title_length', 'selftext_length', 'created_utc', 'subreddit', 'subreddit_id']\n",
      "\n",
      "Sample document:\n",
      "When is the speech?  I thought it was at 7 pm? like right now!...\n"
     ]
    }
   ],
   "source": [
    "# Load thread pseudo-documents\n",
    "input_file = INPUT_DIR / 'thread_pseudodocs.parquet'\n",
    "\n",
    "print(f\"Loading data from: {input_file}\")\n",
    "thread_docs = pd.read_parquet(input_file)\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Total documents: {len(thread_docs):,}\")\n",
    "print(f\"  Date range: {thread_docs['created_utc'].min()} to {thread_docs['created_utc'].max()}\")\n",
    "print(f\"  Columns: {list(thread_docs.columns)}\")\n",
    "print(f\"\\nSample document:\")\n",
    "print(thread_docs['pseudodoc_text'].iloc[0][:500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e696df0",
   "metadata": {},
   "source": [
    "## Initialize Zero-Shot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede5de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: facebook/bart-large-mnli\n",
      "This may take a few minutes on first run...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded successfully\n",
      "\n",
      "Testing classifier on sample document...\n",
      "\n",
      "Sample classification:\n",
      "  Top topic: Media & Free Speech\n",
      "  Confidence: 0.191\n",
      "\n",
      "  Top 3 predictions:\n",
      "    Media & Free Speech: 0.191\n",
      "    Infrastructure: 0.087\n",
      "    Defense & Military: 0.062\n"
     ]
    }
   ],
   "source": [
    "# Initialize zero-shot classification pipeline\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "print(\"This may take a few minutes on first run...\\n\")\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=MODEL_NAME,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model loaded successfully\")\n",
    "\n",
    "# Test on a single document\n",
    "print(\"\\nTesting classifier on sample document...\\n\")\n",
    "test_text = thread_docs['pseudodoc_text'].iloc[0][:512]  # Truncate to 512 tokens\n",
    "\n",
    "test_result = classifier(\n",
    "    test_text,\n",
    "    candidate_labels=topic_labels,\n",
    "    multi_label=False  # Single topic per document\n",
    ")\n",
    "\n",
    "print(f\"Sample classification:\")\n",
    "print(f\"  Top topic: {test_result['labels'][0]}\")\n",
    "print(f\"  Confidence: {test_result['scores'][0]:.3f}\")\n",
    "print(f\"\\n  Top 3 predictions:\")\n",
    "for label, score in zip(test_result['labels'][:3], test_result['scores'][:3]):\n",
    "    print(f\"    {label}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd00eb4",
   "metadata": {},
   "source": [
    "## Classify All Documents\n",
    "\n",
    "Process documents in batches for efficiency. This may take 30-60 minutes for ~430k documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c22c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 433,973 documents...\n",
      "Batch size: 16\n",
      "Estimated time: ~2712-5424 minutes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be444e6c32b45548a6f62d8c6cbd4a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying:   0%|          | 0/27124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m batch = documents_truncated[i:i + BATCH_SIZE]\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Classify batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m results = \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtopic_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Handle single document vs batch results\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:209\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__call__\u001b[39m\u001b[34m(self, sequences, *args, **kwargs)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1448\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1445\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1446\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1447\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:126\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:271\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    268\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    273\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/base.py:1374\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1372\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1373\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/pipelines/zero_shot_classification.py:232\u001b[39m, in \u001b[36mZeroShotClassificationPipeline._forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters:\n\u001b[32m    231\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m model_outputs = {\n\u001b[32m    235\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_label\u001b[39m\u001b[33m\"\u001b[39m: candidate_label,\n\u001b[32m    236\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m: sequence,\n\u001b[32m    237\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m: inputs[\u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    238\u001b[39m     **outputs,\n\u001b[32m    239\u001b[39m }\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/transformers/models/bart/modeling_bart.py:1624\u001b[39m, in \u001b[36mBartForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1620\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[32m   1622\u001b[39m eos_mask = input_ids.eq(\u001b[38;5;28mself\u001b[39m.config.eos_token_id).to(hidden_states.device)\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_consecutive\u001b[49m\u001b[43m(\u001b[49m\u001b[43meos_mask\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) > \u001b[32m1\u001b[39m:\n\u001b[32m   1625\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll examples must have the same number of <eos> tokens.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1626\u001b[39m sentence_representation = hidden_states[eos_mask, :].view(hidden_states.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m, hidden_states.size(-\u001b[32m1\u001b[39m))[\n\u001b[32m   1627\u001b[39m     :, -\u001b[32m1\u001b[39m, :\n\u001b[32m   1628\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/_jit_internal.py:627\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/_jit_internal.py:627\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/functional.py:1138\u001b[39m, in \u001b[36m_consecutive_return_output\u001b[39m\u001b[34m(input, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_consecutive_impl(\u001b[38;5;28minput\u001b[39m, return_inverse, return_counts, dim)\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m output, _, _ = \u001b[43m_unique_consecutive_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/lib/python3.12/site-packages/torch/functional.py:1019\u001b[39m, in \u001b[36m_unique_consecutive_impl\u001b[39m\u001b[34m(input, return_inverse, return_counts, dim)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   1012\u001b[39m         unique_consecutive,\n\u001b[32m   1013\u001b[39m         (\u001b[38;5;28minput\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1017\u001b[39m         dim=dim,\n\u001b[32m   1018\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m output, inverse_indices, counts = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_consecutive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Prepare documents for classification\n",
    "# Truncate to max 512 tokens to avoid model limits\n",
    "documents = thread_docs['pseudodoc_text'].tolist()\n",
    "documents_truncated = [doc[:2048] for doc in documents]  # Approx 512 tokens\n",
    "\n",
    "print(f\"Classifying {len(documents_truncated):,} documents...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Estimated time: ~{len(documents_truncated) // (BATCH_SIZE * 10)}-{len(documents_truncated) // (BATCH_SIZE * 5)} minutes\\n\")\n",
    "\n",
    "# Initialize storage for results\n",
    "topic_ids = []\n",
    "topic_labels_assigned = []\n",
    "topic_confidences = []\n",
    "all_scores = []  # Store full probability distribution\n",
    "\n",
    "# Process in batches with progress bar\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in tqdm(range(0, len(documents_truncated), BATCH_SIZE), desc=\"Classifying\"):\n",
    "    batch = documents_truncated[i:i + BATCH_SIZE]\n",
    "    \n",
    "    # Classify batch\n",
    "    results = classifier(\n",
    "        batch,\n",
    "        candidate_labels=topic_labels,\n",
    "        multi_label=False\n",
    "    )\n",
    "    \n",
    "    # Handle single document vs batch results\n",
    "    if not isinstance(results, list):\n",
    "        results = [results]\n",
    "    \n",
    "    # Extract results\n",
    "    for result in results:\n",
    "        # Get top prediction\n",
    "        top_label = result['labels'][0]\n",
    "        top_score = result['scores'][0]\n",
    "        \n",
    "        # Find topic ID from label\n",
    "        topic_id = topic_labels.index(top_label)\n",
    "        \n",
    "        topic_ids.append(topic_id)\n",
    "        topic_labels_assigned.append(top_label)\n",
    "        topic_confidences.append(top_score)\n",
    "        \n",
    "        # Store full probability distribution (aligned with topic IDs 0-19)\n",
    "        score_dict = {label: score for label, score in zip(result['labels'], result['scores'])}\n",
    "        aligned_scores = [score_dict[label] for label in topic_labels]\n",
    "        all_scores.append(aligned_scores)\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "print(f\"\\nâœ“ Classification complete!\")\n",
    "print(f\"  Duration: {duration:.1f} minutes\")\n",
    "print(f\"  Throughput: {len(documents_truncated) / duration:.0f} documents/minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075b073",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abdfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to dataframe\n",
    "thread_docs['supervised_topic_id'] = topic_ids\n",
    "thread_docs['supervised_topic_label'] = topic_labels_assigned\n",
    "thread_docs['supervised_topic_confidence'] = topic_confidences\n",
    "\n",
    "# Add full probability distribution (optional, for analysis)\n",
    "for i in range(20):\n",
    "    thread_docs[f'topic_{i}_prob'] = [scores[i] for scores in all_scores]\n",
    "\n",
    "print(\"\\n=== Classification Results ===\")\n",
    "print(f\"\\nTotal documents classified: {len(thread_docs):,}\")\n",
    "print(f\"\\nTopic distribution:\")\n",
    "topic_dist = thread_docs['supervised_topic_label'].value_counts().sort_index()\n",
    "for label, count in topic_dist.items():\n",
    "    pct = count / len(thread_docs) * 100\n",
    "    print(f\"  {label:30s}: {count:7,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nConfidence statistics:\")\n",
    "print(f\"  Mean confidence: {thread_docs['supervised_topic_confidence'].mean():.3f}\")\n",
    "print(f\"  Median confidence: {thread_docs['supervised_topic_confidence'].median():.3f}\")\n",
    "print(f\"  Min confidence: {thread_docs['supervised_topic_confidence'].min():.3f}\")\n",
    "print(f\"  Max confidence: {thread_docs['supervised_topic_confidence'].max():.3f}\")\n",
    "\n",
    "# Low confidence documents (potential misclassifications)\n",
    "low_conf_threshold = 0.3\n",
    "low_conf = thread_docs[thread_docs['supervised_topic_confidence'] < low_conf_threshold]\n",
    "print(f\"\\nLow confidence documents (<{low_conf_threshold}): {len(low_conf):,} ({len(low_conf)/len(thread_docs)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0ea5d",
   "metadata": {},
   "source": [
    "## Visualize Topic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Topic distribution\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# 1. Topic counts\n",
    "topic_counts = thread_docs['supervised_topic_id'].value_counts().sort_index()\n",
    "ax = axes[0]\n",
    "topic_count_labels = [POLITICAL_TOPICS[i]['label'] for i in topic_counts.index]\n",
    "ax.bar(range(len(topic_counts)), topic_counts.values, color='steelblue', alpha=0.7)\n",
    "ax.set_xticks(range(len(topic_counts)))\n",
    "ax.set_xticklabels(topic_count_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Document Count')\n",
    "ax.set_title('Document Distribution Across Political Topics')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Confidence distribution by topic\n",
    "ax = axes[1]\n",
    "topic_conf = thread_docs.groupby('supervised_topic_id')['supervised_topic_confidence'].mean().sort_index()\n",
    "topic_conf_labels = [POLITICAL_TOPICS[i]['label'] for i in topic_conf.index]\n",
    "ax.bar(range(len(topic_conf)), topic_conf.values, color='coral', alpha=0.7)\n",
    "ax.set_xticks(range(len(topic_conf)))\n",
    "ax.set_xticklabels(topic_conf_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Mean Confidence')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "ax.set_title('Mean Classification Confidence by Topic')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'supervised_topic_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93397b",
   "metadata": {},
   "source": [
    "## Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal trends\n",
    "thread_docs['date'] = pd.to_datetime(thread_docs['date_temp'])\n",
    "temporal_df = thread_docs.groupby(['date', 'supervised_topic_label']).size().reset_index(name='count')\n",
    "\n",
    "# Top 5 topics over time\n",
    "top_topics = thread_docs['supervised_topic_label'].value_counts().head(5).index\n",
    "temporal_top = temporal_df[temporal_df['supervised_topic_label'].isin(top_topics)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "for topic in top_topics:\n",
    "    topic_data = temporal_top[temporal_top['supervised_topic_label'] == topic]\n",
    "    ax.plot(topic_data['date'], topic_data['count'], label=topic, marker='o', markersize=3, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Document Count')\n",
    "ax.set_title('Top 5 Topics Over Time (Sep-Oct 2016)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'supervised_temporal_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Temporal analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13fa31",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save main results (without full probability distribution)\n",
    "output_columns = [\n",
    "    'thread_id', 'date_temp', 'pseudodoc_text',\n",
    "    'supervised_topic_id', 'supervised_topic_label', 'supervised_topic_confidence'\n",
    "]\n",
    "\n",
    "output_file = OUTPUT_DIR / 'thread_pseudodocs_with_supervised_topics.parquet'\n",
    "thread_docs[output_columns].to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"âœ“ Main results saved to: {output_file}\")\n",
    "print(f\"  Shape: {thread_docs[output_columns].shape}\")\n",
    "\n",
    "# Save full results with probability distributions (for advanced analysis)\n",
    "output_file_full = OUTPUT_DIR / 'thread_pseudodocs_with_supervised_topics_full.parquet'\n",
    "thread_docs.to_parquet(output_file_full, index=False)\n",
    "\n",
    "print(f\"âœ“ Full results (with probabilities) saved to: {output_file_full}\")\n",
    "print(f\"  Shape: {thread_docs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59f337",
   "metadata": {},
   "source": [
    "## Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69becac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'method': 'zero_shot_classification',\n",
    "    'model': MODEL_NAME,\n",
    "    'taxonomy': 'Comparative Agendas Project (CAP)',\n",
    "    'taxonomy_citation': 'Baumgartner, F. R., Jones, B. D., & Wilkerson, J. (2011). Comparative Studies of Policy Agendas. Journal of European Public Policy, 18(5), 639-653.',\n",
    "    'num_topics': 20,\n",
    "    'topics': POLITICAL_TOPICS,\n",
    "    'num_documents': len(thread_docs),\n",
    "    'date_range': {\n",
    "        'start': str(thread_docs['date_temp'].min()),\n",
    "        'end': str(thread_docs['date_temp'].max())\n",
    "    },\n",
    "    'classification_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'duration_minutes': duration,\n",
    "    'device': 'MPS' if device == 0 and torch.backends.mps.is_available() else 'CUDA' if device >= 0 else 'CPU',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'confidence_stats': {\n",
    "        'mean': float(thread_docs['supervised_topic_confidence'].mean()),\n",
    "        'median': float(thread_docs['supervised_topic_confidence'].median()),\n",
    "        'min': float(thread_docs['supervised_topic_confidence'].min()),\n",
    "        'max': float(thread_docs['supervised_topic_confidence'].max()),\n",
    "        'low_confidence_count': int(len(low_conf)),\n",
    "        'low_confidence_threshold': low_conf_threshold\n",
    "    },\n",
    "    'topic_distribution': {\n",
    "        topic_label: int(count) \n",
    "        for topic_label, count in thread_docs['supervised_topic_label'].value_counts().items()\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = OUTPUT_DIR / 'supervised_classification_metadata.json'\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Metadata saved to: {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7360ed",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUPERVISED TOPIC CLASSIFICATION - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset:\")\n",
    "print(f\"  Documents classified: {len(thread_docs):,}\")\n",
    "print(f\"  Date range: {thread_docs['date_temp'].min()} to {thread_docs['date_temp'].max()}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Method:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Taxonomy: Comparative Agendas Project (CAP)\")\n",
    "print(f\"  Number of topics: 20\")\n",
    "\n",
    "print(f\"\\nâš¡ Performance:\")\n",
    "print(f\"  Duration: {duration:.1f} minutes\")\n",
    "print(f\"  Throughput: {len(thread_docs) / duration:.0f} documents/minute\")\n",
    "print(f\"  Device: {metadata['device']}\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Results:\")\n",
    "print(f\"  Mean confidence: {thread_docs['supervised_topic_confidence'].mean():.3f}\")\n",
    "print(f\"  Median confidence: {thread_docs['supervised_topic_confidence'].median():.3f}\")\n",
    "print(f\"  Low confidence (<{low_conf_threshold}): {len(low_conf):,} ({len(low_conf)/len(thread_docs)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ† Top 5 Topics:\")\n",
    "for i, (topic, count) in enumerate(thread_docs['supervised_topic_label'].value_counts().head(5).items(), 1):\n",
    "    pct = count / len(thread_docs) * 100\n",
    "    print(f\"  {i}. {topic:30s}: {count:7,} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Output Files:\")\n",
    "print(f\"  Main results: {output_file.name}\")\n",
    "print(f\"  Full results: {output_file_full.name}\")\n",
    "print(f\"  Metadata: {metadata_file.name}\")\n",
    "print(f\"  Visualizations: supervised_topic_distribution.png, supervised_temporal_trends.png\")\n",
    "\n",
    "print(\"\\nâœ“ Classification complete!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Run notebook 16b for quality assessment\")\n",
    "print(\"  2. Compare with STM/NMF (16 passing) and BERTopic (15 passing)\")\n",
    "print(\"  3. Validate low-confidence documents\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
