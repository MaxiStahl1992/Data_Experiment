{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191ad65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment\n",
      "Python version: 3.12.0 (v3.12.0:0fb18b02c8, Oct  2 2023, 09:45:56) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "✓ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "workspace_root = Path.cwd()\n",
    "sys.path.insert(0, str(workspace_root / 'src'))\n",
    "\n",
    "print(f\"Project root: {workspace_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"✓ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06215e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thesis pipeline utilities\n",
    "from thesis_pipeline.io.parquet import read_parquet, write_parquet\n",
    "\n",
    "# Plotting setup\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d6a82",
   "metadata": {},
   "source": [
    "## 1. Load Filtered Data\n",
    "\n",
    "Load comments and submissions with topic assignments from notebook 15b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82806006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/02_topics/reddit\n",
      "Output: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/data/03_stance/reddit\n",
      "\n",
      "Validating input files:\n",
      "  Comments: True\n",
      "  Submissions: True\n",
      "  Topic definitions: True\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "topics_path = workspace_root / 'data' / '02_topics' / 'reddit'\n",
    "output_path = workspace_root / 'data' / '03_stance' / 'reddit'\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Input: {topics_path}\")\n",
    "print(f\"Output: {output_path}\")\n",
    "\n",
    "# Check files exist\n",
    "print(f\"\\nValidating input files:\")\n",
    "print(f\"  Comments: {(topics_path / 'comments_with_topics.parquet').exists()}\")\n",
    "print(f\"  Submissions: {(topics_path / 'submissions_with_topics.parquet').exists()}\")\n",
    "print(f\"  Topic definitions: {(topics_path / 'topic_definitions.json').exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc06e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading filtered data...\")\n",
    "\n",
    "df_comments = read_parquet(topics_path / 'comments_with_topics.parquet')\n",
    "df_submissions = read_parquet(topics_path / 'submissions_with_topics.parquet')\n",
    "\n",
    "with open(topics_path / 'topic_definitions.json', 'r') as f:\n",
    "    topic_definitions = json.load(f)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df_comments):,} comments\")\n",
    "print(f\"✓ Loaded {len(df_submissions):,} submissions\")\n",
    "print(f\"✓ Loaded {len(topic_definitions)} topic definitions\")\n",
    "\n",
    "print(f\"\\nComment columns: {df_comments.columns.tolist()}\")\n",
    "print(f\"\\nTopic distribution:\")\n",
    "for topic_id, count in df_comments['topic_id'].value_counts().items():\n",
    "    topic_label = topic_definitions[topic_id]['label']\n",
    "    print(f\"  {topic_label}: {count:,} comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e43c5",
   "metadata": {},
   "source": [
    "## 2. Define Stance Categories\n",
    "\n",
    "Define clear stance definitions for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88350810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stance categories for each topic\n",
    "stance_definitions = {\n",
    "    'climate_change': {\n",
    "        'topic_label': 'Climate Change',\n",
    "        'target_position': 'Climate change is real, human-caused, and requires action',\n",
    "        'pro': {\n",
    "            'label': 'Pro (Favor)',\n",
    "            'description': 'Supports climate action, acknowledges human-caused climate change, advocates for environmental policies',\n",
    "            'examples': [\n",
    "                'We need to transition to renewable energy now',\n",
    "                'The science is clear - humans are causing global warming',\n",
    "                'Carbon emissions must be reduced immediately'\n",
    "            ]\n",
    "        },\n",
    "        'against': {\n",
    "            'label': 'Against (Oppose)',\n",
    "            'description': 'Denies climate change, opposes climate action, questions climate science',\n",
    "            'examples': [\n",
    "                'Climate change is a hoax',\n",
    "                'The earth naturally goes through temperature cycles',\n",
    "                'Environmental regulations hurt the economy'\n",
    "            ]\n",
    "        },\n",
    "        'neutral': {\n",
    "            'label': 'Neutral',\n",
    "            'description': 'Neither supports nor opposes, asks questions, presents both sides, unclear stance',\n",
    "            'examples': [\n",
    "                'What do experts say about this?',\n",
    "                'I\\'m not sure what to believe',\n",
    "                'There are arguments on both sides'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'donald_trump': {\n",
    "        'topic_label': 'Donald Trump',\n",
    "        'target_position': 'Donald Trump as president and his policies',\n",
    "        'pro': {\n",
    "            'label': 'Pro (Support Trump)',\n",
    "            'description': 'Supports Trump, defends his actions/policies, positive about his presidency',\n",
    "            'examples': [\n",
    "                'Trump is making America great again',\n",
    "                'Finally a president who keeps his promises',\n",
    "                'Best economy we\\'ve had in decades under Trump'\n",
    "            ]\n",
    "        },\n",
    "        'against': {\n",
    "            'label': 'Against (Oppose Trump)',\n",
    "            'description': 'Opposes Trump, criticizes his actions/policies, negative about his presidency',\n",
    "            'examples': [\n",
    "                'Trump is unfit for office',\n",
    "                'His policies are hurting Americans',\n",
    "                'He\\'s an embarrassment to the country'\n",
    "            ]\n",
    "        },\n",
    "        'neutral': {\n",
    "            'label': 'Neutral',\n",
    "            'description': 'Neither supports nor opposes, factual reporting, balanced view, unclear stance',\n",
    "            'examples': [\n",
    "                'Trump signed this executive order today',\n",
    "                'Some policies I agree with, others I don\\'t',\n",
    "                'What are the details of this decision?'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'gun_control': {\n",
    "        'topic_label': 'Gun Control',\n",
    "        'target_position': 'Stricter gun control and regulations',\n",
    "        'pro': {\n",
    "            'label': 'Pro (Support Gun Control)',\n",
    "            'description': 'Supports stricter gun laws, advocates for regulations, emphasizes public safety',\n",
    "            'examples': [\n",
    "                'We need universal background checks',\n",
    "                'Assault weapons should be banned',\n",
    "                'Common sense gun laws save lives'\n",
    "            ]\n",
    "        },\n",
    "        'against': {\n",
    "            'label': 'Against (Oppose Gun Control)',\n",
    "            'description': 'Opposes gun restrictions, defends Second Amendment rights, pro-gun ownership',\n",
    "            'examples': [\n",
    "                'Shall not be infringed',\n",
    "                'Gun control only hurts law-abiding citizens',\n",
    "                'More guns means more safety'\n",
    "            ]\n",
    "        },\n",
    "        'neutral': {\n",
    "            'label': 'Neutral',\n",
    "            'description': 'Neither strongly pro nor anti gun control, balanced view, unclear stance',\n",
    "            'examples': [\n",
    "                'Both sides have valid points',\n",
    "                'What regulations are being proposed?',\n",
    "                'I support some measures but not others'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'immigration': {\n",
    "        'topic_label': 'Immigration',\n",
    "        'target_position': 'More open/liberal immigration policies',\n",
    "        'pro': {\n",
    "            'label': 'Pro (Support Immigration)',\n",
    "            'description': 'Supports immigrants, advocates for reform/pathways to citizenship, opposes harsh restrictions',\n",
    "            'examples': [\n",
    "                'We should welcome refugees',\n",
    "                'Dreamers deserve a path to citizenship',\n",
    "                'Immigration strengthens our economy'\n",
    "            ]\n",
    "        },\n",
    "        'against': {\n",
    "            'label': 'Against (Restrict Immigration)',\n",
    "            'description': 'Opposes immigration, supports border wall/restrictions, anti-illegal immigration',\n",
    "            'examples': [\n",
    "                'Build the wall',\n",
    "                'Illegal immigration is out of control',\n",
    "                'We need to protect our borders'\n",
    "            ]\n",
    "        },\n",
    "        'neutral': {\n",
    "            'label': 'Neutral',\n",
    "            'description': 'Neither strongly pro nor anti immigration, balanced view, unclear stance',\n",
    "            'examples': [\n",
    "                'We need legal immigration reform',\n",
    "                'What are the economic impacts?',\n",
    "                'There must be a middle ground'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'vaccination': {\n",
    "        'topic_label': 'Vaccination',\n",
    "        'target_position': 'Vaccines are safe, effective, and should be widely used',\n",
    "        'pro': {\n",
    "            'label': 'Pro (Support Vaccination)',\n",
    "            'description': 'Supports vaccines, advocates for vaccination, trusts medical science',\n",
    "            'examples': [\n",
    "                'Vaccines save lives',\n",
    "                'The science is clear on vaccine safety',\n",
    "                'Everyone should get vaccinated'\n",
    "            ]\n",
    "        },\n",
    "        'against': {\n",
    "            'label': 'Against (Anti-Vaccine)',\n",
    "            'description': 'Opposes vaccines, questions vaccine safety, anti-mandate',\n",
    "            'examples': [\n",
    "                'Vaccines are dangerous',\n",
    "                'Natural immunity is better',\n",
    "                'No one should be forced to vaccinate'\n",
    "            ]\n",
    "        },\n",
    "        'neutral': {\n",
    "            'label': 'Neutral',\n",
    "            'description': 'Neither strongly pro nor anti vaccine, questions/concerns, unclear stance',\n",
    "            'examples': [\n",
    "                'What are the long-term effects?',\n",
    "                'I have some vaccines but not others',\n",
    "                'More research is needed'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Defined stance categories for all topics:\")\n",
    "for topic_id, stance_def in stance_definitions.items():\n",
    "    print(f\"\\n{stance_def['topic_label']}:\")\n",
    "    print(f\"  Target: {stance_def['target_position']}\")\n",
    "    print(f\"  Categories: Pro / Against / Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b00391",
   "metadata": {},
   "source": [
    "## 3. Sampling Strategy\n",
    "\n",
    "Sample 100 comments per topic using stratified sampling to ensure diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be778fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling parameters\n",
    "SAMPLES_PER_TOPIC = 100\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Sampling strategy:\")\n",
    "print(f\"  Target: {SAMPLES_PER_TOPIC} comments per topic\")\n",
    "print(f\"  Total target: {SAMPLES_PER_TOPIC * len(topic_definitions)} comments\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "\n",
    "# Add text length for filtering\n",
    "df_comments['text_length'] = df_comments['body'].str.len()\n",
    "\n",
    "print(f\"\\nText length statistics:\")\n",
    "print(df_comments['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter criteria for annotation quality\n",
    "print(\"Applying filters for annotation quality...\\n\")\n",
    "\n",
    "# Filter 1: Minimum length (exclude very short comments)\n",
    "MIN_LENGTH = 50\n",
    "print(f\"Filter 1: Minimum length = {MIN_LENGTH} characters\")\n",
    "df_filtered = df_comments[df_comments['text_length'] >= MIN_LENGTH].copy()\n",
    "print(f\"  Remaining: {len(df_filtered):,} comments ({len(df_filtered)/len(df_comments)*100:.1f}%)\")\n",
    "\n",
    "# Filter 2: Exclude deleted/removed\n",
    "print(f\"\\nFilter 2: Exclude [deleted] and [removed]\")\n",
    "df_filtered = df_filtered[\n",
    "    ~df_filtered['body'].isin(['[deleted]', '[removed]'])\n",
    "].copy()\n",
    "print(f\"  Remaining: {len(df_filtered):,} comments ({len(df_filtered)/len(df_comments)*100:.1f}%)\")\n",
    "\n",
    "# Filter 3: Exclude AutoModerator\n",
    "if 'author' in df_filtered.columns:\n",
    "    print(f\"\\nFilter 3: Exclude AutoModerator\")\n",
    "    df_filtered = df_filtered[\n",
    "        df_filtered['author'] != 'AutoModerator'\n",
    "    ].copy()\n",
    "    print(f\"  Remaining: {len(df_filtered):,} comments ({len(df_filtered)/len(df_comments)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nFiltered corpus:\")\n",
    "print(f\"  Original: {len(df_comments):,} comments\")\n",
    "print(f\"  Filtered: {len(df_filtered):,} comments\")\n",
    "print(f\"  Reduction: {(1 - len(df_filtered)/len(df_comments))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nComments per topic (after filtering):\")\n",
    "for topic_id, count in df_filtered['topic_id'].value_counts().items():\n",
    "    topic_label = topic_definitions[topic_id]['label']\n",
    "    print(f\"  {topic_label}: {count:,} comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1428cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling per topic\n",
    "print(f\"Sampling {SAMPLES_PER_TOPIC} comments per topic...\\n\")\n",
    "\n",
    "sampled_dfs = []\n",
    "\n",
    "for topic_id, topic_info in topic_definitions.items():\n",
    "    topic_label = topic_info['label']\n",
    "    \n",
    "    # Get comments for this topic\n",
    "    topic_comments = df_filtered[df_filtered['topic_id'] == topic_id].copy()\n",
    "    \n",
    "    print(f\"{topic_label}:\")\n",
    "    print(f\"  Available: {len(topic_comments):,} comments\")\n",
    "    \n",
    "    if len(topic_comments) < SAMPLES_PER_TOPIC:\n",
    "        print(f\"  WARNING: Only {len(topic_comments)} comments available (< {SAMPLES_PER_TOPIC} target)\")\n",
    "        sample = topic_comments.copy()\n",
    "    else:\n",
    "        # Stratified sampling by text length quartiles\n",
    "        # This ensures diversity in comment length\n",
    "        topic_comments['length_quartile'] = pd.qcut(\n",
    "            topic_comments['text_length'], \n",
    "            q=4, \n",
    "            labels=['Q1', 'Q2', 'Q3', 'Q4'],\n",
    "            duplicates='drop'\n",
    "        )\n",
    "        \n",
    "        # Sample proportionally from each quartile\n",
    "        sample = topic_comments.groupby('length_quartile', group_keys=False).apply(\n",
    "            lambda x: x.sample(n=min(len(x), SAMPLES_PER_TOPIC // 4), random_state=RANDOM_SEED)\n",
    "        )\n",
    "        \n",
    "        # If we don't have enough, randomly sample remainder\n",
    "        if len(sample) < SAMPLES_PER_TOPIC:\n",
    "            remaining_needed = SAMPLES_PER_TOPIC - len(sample)\n",
    "            remaining_pool = topic_comments[~topic_comments.index.isin(sample.index)]\n",
    "            additional = remaining_pool.sample(n=min(len(remaining_pool), remaining_needed), random_state=RANDOM_SEED)\n",
    "            sample = pd.concat([sample, additional])\n",
    "    \n",
    "    print(f\"  Sampled: {len(sample)} comments\")\n",
    "    \n",
    "    sampled_dfs.append(sample)\n",
    "    print()\n",
    "\n",
    "# Combine all samples\n",
    "df_annotation_set = pd.concat(sampled_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Total sampled: {len(df_annotation_set):,} comments\")\n",
    "print(f\"\\nSamples per topic:\")\n",
    "for topic_id, count in df_annotation_set['topic_id'].value_counts().items():\n",
    "    topic_label = topic_definitions[topic_id]['label']\n",
    "    print(f\"  {topic_label}: {count} comments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbfdd1",
   "metadata": {},
   "source": [
    "## 4. Prepare Annotation Dataset\n",
    "\n",
    "Add submission context and prepare columns for annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add submission titles for context\n",
    "print(\"Adding submission context...\")\n",
    "\n",
    "# Create submission lookup\n",
    "submission_lookup = df_submissions.set_index('submission_id')[['title', 'subreddit']].to_dict('index')\n",
    "\n",
    "df_annotation_set['submission_title'] = df_annotation_set['submission_id'].map(\n",
    "    lambda x: submission_lookup.get(x, {}).get('title', 'N/A')\n",
    ")\n",
    "\n",
    "df_annotation_set['subreddit'] = df_annotation_set['submission_id'].map(\n",
    "    lambda x: submission_lookup.get(x, {}).get('subreddit', 'N/A')\n",
    ")\n",
    "\n",
    "print(f\"✓ Added submission context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b99860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add annotation columns\n",
    "print(\"Preparing annotation columns...\")\n",
    "\n",
    "df_annotation_set['stance_label'] = None  # To be filled: 'pro', 'against', 'neutral'\n",
    "df_annotation_set['annotation_confidence'] = None  # Optional: 'high', 'medium', 'low'\n",
    "df_annotation_set['annotation_notes'] = ''  # Optional: Any notes\n",
    "df_annotation_set['annotator'] = ''  # Annotator ID\n",
    "df_annotation_set['annotation_date'] = None\n",
    "\n",
    "# Add unique ID for tracking\n",
    "df_annotation_set['annotation_id'] = [\n",
    "    f\"ANN_{i:05d}\" for i in range(1, len(df_annotation_set) + 1)\n",
    "]\n",
    "\n",
    "print(f\"✓ Added annotation columns\")\n",
    "print(f\"\\nAnnotation columns: {['annotation_id', 'stance_label', 'annotation_confidence', 'annotation_notes', 'annotator', 'annotation_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41762f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for annotation workflow\n",
    "annotation_cols = [\n",
    "    'annotation_id',\n",
    "    'topic_id',\n",
    "    'submission_title',\n",
    "    'body',\n",
    "    'stance_label',\n",
    "    'annotation_confidence',\n",
    "    'annotation_notes',\n",
    "    'annotator',\n",
    "    'annotation_date',\n",
    "    'comment_id',\n",
    "    'submission_id',\n",
    "    'subreddit',\n",
    "    'text_length',\n",
    "    'created_utc',\n",
    "    'score',\n",
    "    'author'\n",
    "]\n",
    "\n",
    "# Only include columns that exist\n",
    "available_cols = [col for col in annotation_cols if col in df_annotation_set.columns]\n",
    "\n",
    "df_annotation_set = df_annotation_set[available_cols].copy()\n",
    "\n",
    "print(f\"✓ Reordered columns for annotation\")\n",
    "print(f\"\\nFinal columns: {df_annotation_set.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028fa776",
   "metadata": {},
   "source": [
    "## 5. Save Annotation Dataset\n",
    "\n",
    "Save the prepared dataset and create annotation guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef763fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save annotation dataset\n",
    "annotation_file = output_path / 'stance_annotation_dataset.parquet'\n",
    "write_parquet(df_annotation_set, annotation_file)\n",
    "\n",
    "print(f\"✓ Saved annotation dataset: {annotation_file}\")\n",
    "print(f\"  {len(df_annotation_set):,} comments ready for annotation\")\n",
    "print(f\"  {df_annotation_set.memory_usage(deep=True).sum() / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stance definitions\n",
    "stance_def_file = output_path / 'stance_definitions.json'\n",
    "\n",
    "with open(stance_def_file, 'w') as f:\n",
    "    json.dump(stance_definitions, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved stance definitions: {stance_def_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation guidelines document\n",
    "guidelines = f\"\"\"# Stance Annotation Guidelines\n",
    "\n",
    "**Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
    "**Dataset**: {len(df_annotation_set)} comments across 5 topics\n",
    "**Target**: Tri-class stance (Pro/Against/Neutral) per topic\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "You will annotate comments for their **stance** (position) toward specific topics. For each comment, determine whether the author:\n",
    "- **Supports/Favors** the topic (Pro)\n",
    "- **Opposes** the topic (Against)  \n",
    "- Takes a **Neutral** position or unclear stance\n",
    "\n",
    "---\n",
    "\n",
    "## General Guidelines\n",
    "\n",
    "### 1. Focus on the Comment Text\n",
    "- Base your judgment on what the comment says, not your personal opinion\n",
    "- Consider the submission title for context, but label the **comment's** stance\n",
    "\n",
    "### 2. Stance vs. Sentiment\n",
    "- **Stance** = Position toward the topic (support/oppose)\n",
    "- **Sentiment** = Emotional tone (positive/negative)\n",
    "- These can differ! Example: \"I hate to admit it but Trump is right\" = Pro-Trump stance, negative sentiment\n",
    "\n",
    "### 3. Explicit vs. Implicit Stance\n",
    "- Look for **explicit** statements: \"I support...\", \"I'm against...\"\n",
    "- Also consider **implicit** cues: Sarcasm, rhetorical questions, implications\n",
    "- Example: \"Sure, let's just ignore science...\" (sarcastic = Against climate action)\n",
    "\n",
    "### 4. When to Choose Neutral\n",
    "- Asks questions without revealing stance\n",
    "- Presents both sides equally\n",
    "- Off-topic or unclear\n",
    "- Genuinely ambiguous (when in doubt, choose Neutral)\n",
    "\n",
    "### 5. Confidence Levels (Optional)\n",
    "- **High**: Clear, unambiguous stance\n",
    "- **Medium**: Reasonably clear but some ambiguity\n",
    "- **Low**: Difficult to determine, borderline case\n",
    "\n",
    "---\n",
    "\n",
    "## Topic-Specific Definitions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add topic-specific guidelines\n",
    "for topic_id, stance_def in stance_definitions.items():\n",
    "    guidelines += f\"\"\"\\n### {stance_def['topic_label']}\n",
    "\n",
    "**Target Position**: {stance_def['target_position']}\n",
    "\n",
    "**Pro (Support)**: {stance_def['pro']['description']}\n",
    "Examples:\n",
    "\"\"\"\n",
    "    for ex in stance_def['pro']['examples']:\n",
    "        guidelines += f\"- \\\"{ex}\\\"\\n\"\n",
    "    \n",
    "    guidelines += f\"\\n**Against (Oppose)**: {stance_def['against']['description']}\\nExamples:\\n\"\n",
    "    for ex in stance_def['against']['examples']:\n",
    "        guidelines += f\"- \\\"{ex}\\\"\\n\"\n",
    "    \n",
    "    guidelines += f\"\\n**Neutral**: {stance_def['neutral']['description']}\\nExamples:\\n\"\n",
    "    for ex in stance_def['neutral']['examples']:\n",
    "        guidelines += f\"- \\\"{ex}\\\"\\n\"\n",
    "    \n",
    "    guidelines += \"\\n---\\n\"\n",
    "\n",
    "# Add annotation workflow\n",
    "guidelines += f\"\"\"\n",
    "## Annotation Workflow\n",
    "\n",
    "### Setup\n",
    "1. Load `stance_annotation_dataset.parquet` in a notebook or annotation tool\n",
    "2. Read these guidelines thoroughly\n",
    "3. Start with a few examples to calibrate\n",
    "\n",
    "### For Each Comment:\n",
    "1. **Read the submission title** (provides topic context)\n",
    "2. **Read the comment body** (what you're labeling)\n",
    "3. **Identify the topic** (shown in `topic_id` column)\n",
    "4. **Determine stance**: Pro / Against / Neutral\n",
    "5. **Record confidence** (optional): High / Medium / Low\n",
    "6. **Add notes** (optional): Explain difficult cases\n",
    "\n",
    "### Filling the Columns:\n",
    "- `stance_label`: Must be one of: 'pro', 'against', 'neutral'\n",
    "- `annotation_confidence`: Optional: 'high', 'medium', 'low'\n",
    "- `annotation_notes`: Optional: Free text for notes\n",
    "- `annotator`: Your initials or ID\n",
    "- `annotation_date`: Today's date (YYYY-MM-DD)\n",
    "\n",
    "### Quality Checks:\n",
    "- Take breaks every 20-30 annotations\n",
    "- If unsure, mark as 'neutral' with low confidence\n",
    "- Note edge cases in `annotation_notes`\n",
    "- Aim for consistency across similar comments\n",
    "\n",
    "---\n",
    "\n",
    "## Example Annotations\n",
    "\n",
    "### Example 1: Clear Pro\n",
    "**Topic**: Climate Change  \n",
    "**Title**: \"New climate report shows accelerating warming\"  \n",
    "**Comment**: \"We need to act now. Renewable energy is our only hope.\"  \n",
    "**Label**: `pro`  \n",
    "**Confidence**: `high`\n",
    "\n",
    "### Example 2: Clear Against\n",
    "**Topic**: Gun Control  \n",
    "**Title**: \"Lawmakers propose assault weapon ban\"  \n",
    "**Comment**: \"Shall not be infringed. This is unconstitutional.\"  \n",
    "**Label**: `against`  \n",
    "**Confidence**: `high`\n",
    "\n",
    "### Example 3: Neutral - Question\n",
    "**Topic**: Vaccination  \n",
    "**Title**: \"New vaccine guidelines released\"  \n",
    "**Comment**: \"What do the long-term studies show? I'd like to see more data.\"  \n",
    "**Label**: `neutral`  \n",
    "**Confidence**: `high`\n",
    "\n",
    "### Example 4: Implicit Stance (Sarcasm)\n",
    "**Topic**: Donald Trump  \n",
    "**Title**: \"Trump claims election was rigged\"  \n",
    "**Comment**: \"Sure, and I'm the Queen of England. Give me a break.\"  \n",
    "**Label**: `against` (sarcastic = opposing Trump's claim)  \n",
    "**Confidence**: `medium`\n",
    "\n",
    "### Example 5: Neutral - Balanced View\n",
    "**Topic**: Immigration  \n",
    "**Title**: \"Border wall debate continues\"  \n",
    "**Comment**: \"Both sides have valid concerns. We need comprehensive reform that addresses security and compassion.\"  \n",
    "**Label**: `neutral`  \n",
    "**Confidence**: `high`\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### \"The comment doesn't mention the topic\"\n",
    "→ Consider context. If it's clearly related (e.g., in a climate subreddit), stance may be implicit\n",
    "\n",
    "### \"I genuinely can't tell\"\n",
    "→ Label as `neutral` with `low` confidence. Add notes explaining why.\n",
    "\n",
    "### \"The comment is sarcastic\"\n",
    "→ Try to infer the actual stance. Sarcasm usually implies the opposite of what's said literally.\n",
    "\n",
    "### \"The comment has mixed stance\"\n",
    "→ Choose the **dominant** stance. If truly balanced, use `neutral`.\n",
    "\n",
    "---\n",
    "\n",
    "## After Annotation\n",
    "\n",
    "When complete:\n",
    "1. Save the annotated file: `stance_annotation_dataset_annotated.parquet`\n",
    "2. Check for missing values in `stance_label` column\n",
    "3. Review a random sample for consistency\n",
    "4. Calculate inter-annotator agreement if multiple annotators\n",
    "\n",
    "The annotated dataset will be used in notebook **16b** to train the stance detection model.\n",
    "\n",
    "---\n",
    "\n",
    "**Questions?** Document them in your annotation notes for discussion.\n",
    "\"\"\"\n",
    "\n",
    "# Save guidelines\n",
    "guidelines_file = output_path / 'stance_annotation_guidelines.md'\n",
    "with open(guidelines_file, 'w') as f:\n",
    "    f.write(guidelines)\n",
    "\n",
    "print(f\"✓ Saved annotation guidelines: {guidelines_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6429423",
   "metadata": {},
   "source": [
    "## 6. Preview Annotation Dataset\n",
    "\n",
    "Show examples from the annotation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample annotations per topic\n",
    "print(\"=\" * 80)\n",
    "print(\"ANNOTATION DATASET PREVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for topic_id in df_annotation_set['topic_id'].unique():\n",
    "    topic_label = topic_definitions[topic_id]['label']\n",
    "    topic_samples = df_annotation_set[df_annotation_set['topic_id'] == topic_id].head(3)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{topic_label.upper()} - Sample Annotations\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for idx, (_, row) in enumerate(topic_samples.iterrows(), 1):\n",
    "        print(f\"\\n[{idx}] ID: {row['annotation_id']}\")\n",
    "        print(f\"    Submission: {row['submission_title'][:80]}...\")\n",
    "        print(f\"    Subreddit: r/{row['subreddit']}\")\n",
    "        print(f\"    Comment ({row['text_length']} chars):\")\n",
    "        print(f\"    \\\"{row['body'][:200]}...\\\"\")\n",
    "        print(f\"    → Stance label: [TO BE ANNOTATED]\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first few rows of dataset\n",
    "print(\"\\nFirst 5 rows of annotation dataset:\")\n",
    "df_annotation_set[[\n",
    "    'annotation_id', 'topic_id', 'submission_title', 'body', 'stance_label'\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2a400",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "Generate summary of annotation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary\n",
    "summary = {\n",
    "    'notebook': '16a_stance_annotation_sampling',\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'sampling': {\n",
    "        'target_per_topic': SAMPLES_PER_TOPIC,\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'min_text_length': MIN_LENGTH,\n",
    "        'strategy': 'stratified by text length quartiles'\n",
    "    },\n",
    "    'dataset': {\n",
    "        'total_comments': len(df_annotation_set),\n",
    "        'topics': len(topic_definitions),\n",
    "        'samples_per_topic': df_annotation_set['topic_id'].value_counts().to_dict()\n",
    "    },\n",
    "    'text_statistics': {\n",
    "        'mean_length': float(df_annotation_set['text_length'].mean()),\n",
    "        'median_length': float(df_annotation_set['text_length'].median()),\n",
    "        'min_length': int(df_annotation_set['text_length'].min()),\n",
    "        'max_length': int(df_annotation_set['text_length'].max())\n",
    "    },\n",
    "    'outputs': {\n",
    "        'annotation_dataset': str(annotation_file),\n",
    "        'stance_definitions': str(stance_def_file),\n",
    "        'guidelines': str(guidelines_file)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = output_path / '16a_sampling_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved summary: {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANNOTATION DATASET READY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n✓ Sampled {len(df_annotation_set):,} comments for annotation\")\n",
    "print(f\"\\nSamples per topic:\")\n",
    "for topic_id, count in df_annotation_set['topic_id'].value_counts().items():\n",
    "    topic_label = topic_definitions[topic_id]['label']\n",
    "    print(f\"  {topic_label}: {count} comments\")\n",
    "\n",
    "print(f\"\\n✓ Created files:\")\n",
    "print(f\"  {annotation_file}\")\n",
    "print(f\"  {stance_def_file}\")\n",
    "print(f\"  {guidelines_file}\")\n",
    "print(f\"  {summary_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. MANUAL ANNOTATION:\")\n",
    "print(\"   - Read the annotation guidelines thoroughly\")\n",
    "print(\"   - Load the annotation dataset\")\n",
    "print(\"   - Fill in 'stance_label' column: 'pro', 'against', or 'neutral'\")\n",
    "print(\"   - Optionally add confidence and notes\")\n",
    "print(\"   - Save as 'stance_annotation_dataset_annotated.parquet'\")\n",
    "\n",
    "print(\"\\n2. QUALITY CHECKS:\")\n",
    "print(\"   - Ensure all rows have stance_label filled\")\n",
    "print(\"   - Review a random sample for consistency\")\n",
    "print(\"   - If multiple annotators, calculate inter-annotator agreement\")\n",
    "\n",
    "print(\"\\n3. PROCEED TO NOTEBOOK 16b:\")\n",
    "print(\"   - Use annotated dataset to train stance detection model\")\n",
    "print(\"   - Apply model to all filtered comments\")\n",
    "print(\"   - Validate on held-out annotations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
