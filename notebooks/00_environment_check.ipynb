{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979f0c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation run started: 2025-12-18T14:02:02.018358\n",
      "Platform: macOS-15.7.2-arm64-arm-64bit-Mach-O\n",
      "Machine: arm64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Validation run started: {datetime.now().isoformat()}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Machine: {platform.machine()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5284f3e",
   "metadata": {},
   "source": [
    "## 1. Python Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b04b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.5\n",
      "Executable: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment/venv/bin/python\n",
      "✓ Python version matches expected: 3.13.5\n"
     ]
    }
   ],
   "source": [
    "# Expected: Python 3.13.5\n",
    "python_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "print(f\"Python version: {python_version}\")\n",
    "print(f\"Executable: {sys.executable}\")\n",
    "\n",
    "expected_version = \"3.13.5\"\n",
    "if python_version == expected_version:\n",
    "    print(f\"✓ Python version matches expected: {expected_version}\")\n",
    "else:\n",
    "    print(f\"⚠ Warning: Expected {expected_version}, got {python_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c282b",
   "metadata": {},
   "source": [
    "## 2. Dependency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b800c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ pandas: 2.2.3\n",
      "✓ pyarrow: 18.1.0\n",
      "✓ numpy: 2.2.1\n",
      "✓ xxhash: unknown\n",
      "✓ pyyaml: 6.0.2\n",
      "✓ datasets: 3.2.0\n",
      "✓ tqdm: 4.67.1\n",
      "✓ matplotlib: 3.9.3\n",
      "✓ seaborn: 0.13.2\n",
      "✓ jsonschema: 4.23.0\n",
      "\n",
      "✓ All dependencies installed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/scf6msw549j5lvz4kv2gfpz00000gn/T/ipykernel_75884/3018538122.py:20: DeprecationWarning: Accessing jsonschema.__version__ is deprecated and will be removed in a future release. Use importlib.metadata directly to query for jsonschema's version.\n",
      "  version = getattr(module, '__version__', 'unknown')\n"
     ]
    }
   ],
   "source": [
    "# Import all required packages\n",
    "dependencies = {\n",
    "    'pandas': None,\n",
    "    'pyarrow': None,\n",
    "    'numpy': None,\n",
    "    'xxhash': None,\n",
    "    'yaml': 'pyyaml',\n",
    "    'datasets': None,\n",
    "    'tqdm': None,\n",
    "    'matplotlib': None,\n",
    "    'seaborn': None,\n",
    "    'jsonschema': None\n",
    "}\n",
    "\n",
    "import_errors = []\n",
    "\n",
    "for module_name, package_name in dependencies.items():\n",
    "    try:\n",
    "        module = __import__(module_name)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"✓ {package_name or module_name}: {version}\")\n",
    "    except ImportError as e:\n",
    "        import_errors.append((package_name or module_name, str(e)))\n",
    "        print(f\"✗ {package_name or module_name}: NOT INSTALLED\")\n",
    "\n",
    "if import_errors:\n",
    "    print(f\"\\n⚠ {len(import_errors)} package(s) missing. Install with: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\n✓ All dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef37db",
   "metadata": {},
   "source": [
    "## 3. Disk Space Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3421b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace: /Users/stahlma/Desktop/01_Studium/11_Thesis/Data_Experiment\n",
      "Total disk: 926.4 GB\n",
      "Used: 540.8 GB (58.4%)\n",
      "Free: 385.5 GB\n",
      "\n",
      "✓ Sufficient disk space (385.5 GB available, ~50 GB estimated needed)\n"
     ]
    }
   ],
   "source": [
    "# Check available disk space\n",
    "workspace_root = Path.cwd()\n",
    "disk_usage = shutil.disk_usage(workspace_root)\n",
    "\n",
    "gb = 1024**3\n",
    "total_gb = disk_usage.total / gb\n",
    "used_gb = disk_usage.used / gb\n",
    "free_gb = disk_usage.free / gb\n",
    "\n",
    "print(f\"Workspace: {workspace_root}\")\n",
    "print(f\"Total disk: {total_gb:.1f} GB\")\n",
    "print(f\"Used: {used_gb:.1f} GB ({100 * disk_usage.used / disk_usage.total:.1f}%)\")\n",
    "print(f\"Free: {free_gb:.1f} GB\")\n",
    "\n",
    "# Estimate: ~600k news articles + ~? Reddit comments\n",
    "# Conservative estimate: 50 GB needed for raw + processed data\n",
    "required_gb = 50\n",
    "if free_gb >= required_gb:\n",
    "    print(f\"\\n✓ Sufficient disk space ({free_gb:.1f} GB available, ~{required_gb} GB estimated needed)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Warning: Low disk space ({free_gb:.1f} GB available, ~{required_gb} GB estimated needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4320d99",
   "metadata": {},
   "source": [
    "## 4. Configuration Files Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9483d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All configuration files loaded successfully\n",
      "\n",
      "=== Global Config ===\n",
      "Period: 2016-09-01 to 2016-10-31\n",
      "Seed: thesis_sep_oct_2016_v1\n",
      "Python: 3.13.2\n",
      "\n",
      "=== Reddit Config ===\n",
      "Source: Politosphere\n",
      "Time index: created_utc\n",
      "Partitioning: daily\n",
      "\n",
      "=== News Config ===\n",
      "Source: stanford-oval/ccnews\n",
      "Daily limit: 10,000 articles/day\n",
      "Access method: download\n",
      "Partitioning: daily\n"
     ]
    }
   ],
   "source": [
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(workspace_root / 'src'))\n",
    "\n",
    "from thesis_pipeline.io.config import load_all_configs\n",
    "\n",
    "try:\n",
    "    configs = load_all_configs(workspace_root / 'configs')\n",
    "    print(\"✓ All configuration files loaded successfully\\n\")\n",
    "    \n",
    "    # Display key parameters\n",
    "    global_cfg = configs['global']\n",
    "    reddit_cfg = configs['reddit']\n",
    "    news_cfg = configs['news']\n",
    "    \n",
    "    print(\"=== Global Config ===\")\n",
    "    print(f\"Period: {global_cfg['validation_run']['period_start']} to {global_cfg['validation_run']['period_end']}\")\n",
    "    print(f\"Seed: {global_cfg['validation_run']['seed_string']}\")\n",
    "    print(f\"Python: {global_cfg['validation_run']['python_version']}\")\n",
    "    \n",
    "    print(\"\\n=== Reddit Config ===\")\n",
    "    print(f\"Source: {reddit_cfg['source']['name']}\")\n",
    "    print(f\"Time index: {reddit_cfg['processing']['time_index_field']}\")\n",
    "    print(f\"Partitioning: {reddit_cfg['output']['partitioning']}\")\n",
    "    \n",
    "    print(\"\\n=== News Config ===\")\n",
    "    print(f\"Source: {news_cfg['source']['hf_dataset']}\")\n",
    "    print(f\"Daily limit: {news_cfg['sampling']['daily_limit_n']:,} articles/day\")\n",
    "    print(f\"Access method: {news_cfg['source']['access_method']}\")\n",
    "    print(f\"Partitioning: {news_cfg['output']['partitioning']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading configurations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9e63f",
   "metadata": {},
   "source": [
    "## 5. Directory Structure Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e2d785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All required directories exist\n",
      "\n",
      "✓ Directory structure ready\n"
     ]
    }
   ],
   "source": [
    "# Verify all required directories exist\n",
    "required_dirs = [\n",
    "    'data/00_raw/reddit',\n",
    "    'data/00_raw/news',\n",
    "    'data/01_silver/reddit',\n",
    "    'data/01_silver/news',\n",
    "    'data/03_gold/reddit',\n",
    "    'data/03_gold/news',\n",
    "    'data/04_qa/manifests',\n",
    "    'data/04_qa/snapshots',\n",
    "    'reports/data_validation/2016-09_2016-10/reddit/figures',\n",
    "    'reports/data_validation/2016-09_2016-10/reddit/tables',\n",
    "    'reports/data_validation/2016-09_2016-10/news/figures',\n",
    "    'reports/data_validation/2016-09_2016-10/news/tables',\n",
    "    'logs/notebooks',\n",
    "    'logs/runs',\n",
    "    'artefacts/run_metadata'\n",
    "]\n",
    "\n",
    "missing_dirs = []\n",
    "for dir_path in required_dirs:\n",
    "    full_path = workspace_root / dir_path\n",
    "    if not full_path.exists():\n",
    "        missing_dirs.append(dir_path)\n",
    "\n",
    "if missing_dirs:\n",
    "    print(f\"Creating {len(missing_dirs)} missing directories...\")\n",
    "    for dir_path in missing_dirs:\n",
    "        (workspace_root / dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  Created: {dir_path}\")\n",
    "else:\n",
    "    print(\"✓ All required directories exist\")\n",
    "\n",
    "print(\"\\n✓ Directory structure ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab2c9d1",
   "metadata": {},
   "source": [
    "## 6. Git Status Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d124a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git branch: main\n",
      "Git commit: 175129e3...\n",
      "\n",
      "⚠ Uncommitted changes detected:\n",
      "M notebooks/00_environment_check.ipynb\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    # Get current git commit\n",
    "    git_commit = subprocess.check_output(\n",
    "        ['git', 'rev-parse', 'HEAD'],\n",
    "        cwd=workspace_root,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    ).decode().strip()\n",
    "    \n",
    "    git_branch = subprocess.check_output(\n",
    "        ['git', 'rev-parse', '--abbrev-ref', 'HEAD'],\n",
    "        cwd=workspace_root,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    ).decode().strip()\n",
    "    \n",
    "    print(f\"Git branch: {git_branch}\")\n",
    "    print(f\"Git commit: {git_commit[:8]}...\")\n",
    "    \n",
    "    # Check for uncommitted changes\n",
    "    git_status = subprocess.check_output(\n",
    "        ['git', 'status', '--porcelain'],\n",
    "        cwd=workspace_root\n",
    "    ).decode().strip()\n",
    "    \n",
    "    if git_status:\n",
    "        print(\"\\n⚠ Uncommitted changes detected:\")\n",
    "        print(git_status[:500])  # First 500 chars\n",
    "    else:\n",
    "        print(\"\\n✓ Working directory clean\")\n",
    "    \n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"⚠ Not a git repository or git not available\")\n",
    "    git_commit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3977a",
   "metadata": {},
   "source": [
    "## 7. Summary & Readiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7132278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENVIRONMENT CHECK SUMMARY\n",
      "============================================================\n",
      "✓ Python: 3.13.5\n",
      "✓ Dependencies: All installed\n",
      "✓ Disk space: 385.5 GB available\n",
      "✓ Configurations: Loaded\n",
      "✓ Directory structure: Ready\n",
      "✓ Git commit: 175129e3\n",
      "\n",
      "Status: READY TO PROCEED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ENVIRONMENT CHECK SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"✓ Python: {python_version}\")\n",
    "print(f\"✓ Dependencies: All installed\" if not import_errors else f\"✗ Dependencies: {len(import_errors)} missing\")\n",
    "print(f\"✓ Disk space: {free_gb:.1f} GB available\")\n",
    "print(f\"✓ Configurations: Loaded\")\n",
    "print(f\"✓ Directory structure: Ready\")\n",
    "print(f\"✓ Git commit: {git_commit[:8] if git_commit else 'N/A'}\")\n",
    "print(\"\\nStatus: READY TO PROCEED\" if not import_errors else \"Status: INSTALL DEPENDENCIES FIRST\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
